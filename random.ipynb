{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Mmetrics import *\n",
    "\n",
    "import LTR\n",
    "import datautil\n",
    "import permutationgraph\n",
    "import DTR\n",
    "import EEL\n",
    "import PPG\n",
    "import PL\n",
    "\n",
    "\n",
    "def df2ds(df_path):\n",
    "    with open(df_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    ds = df.to_dict(orient='list')\n",
    "    for k in ds:\n",
    "        ds[k] = np.array(ds[k])\n",
    "    ds['dlr'] = np.concatenate([np.zeros(1), np.where(np.diff(ds['qid'])==1)[0]+1, np.array([ds['qid'].shape[0]])]).astype(int)\n",
    "    return type('ltr', (object,), ds)\n",
    "\n",
    "\n",
    "def dict2ds(df_path):\n",
    "    with open(df_path, 'rb') as f:\n",
    "        ds = pickle.load(f)\n",
    "    return type('ltr', (object,), ds)\n",
    "\n",
    "ds2019 = df2ds('LTR2019.df')\n",
    "ds2020 = df2ds('LTR2020.df')\n",
    "\n",
    "def valid_queries(ds):\n",
    "    dtr, eel = [], []\n",
    "    groups = np.unique(ds.g)\n",
    "    for qid in range(ds.dlr.shape[0] - 1):\n",
    "        s, e = ds.dlr[qid:qid+2]\n",
    "        lv = ds.lv[s:e]\n",
    "        g = ds.g[s:e]\n",
    "        z = False\n",
    "        for group in groups:\n",
    "            if lv[g==group].sum() == 0:\n",
    "                z = True\n",
    "                break\n",
    "        if not z:\n",
    "            dtr.append(qid)\n",
    "        if len(np.unique(ds.g[s:e])) > 1:\n",
    "            eel.append(qid)\n",
    "            \n",
    "    return {'DTR':np.array(dtr), 'EEL':np.array(eel)}\n",
    "\n",
    "ds2019.valids = valid_queries(ds2019)\n",
    "ds2020.valids = valid_queries(ds2020)\n",
    "\n",
    "def evaluate_one(metric, qid, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    permutation = output_permutation\n",
    "    lv_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=lv[s:e], g=g[s:e], sorted_docs=lv[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    \n",
    "    if metric == 'EEL':\n",
    "        objective_ins = EEL.EEL(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = 2)\n",
    "    else:\n",
    "        objective_ins = DTR.DTR(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure)\n",
    "        \n",
    "    \n",
    "    osl = e - s\n",
    "    argsort = lv[s:e].argsort()[::-1]\n",
    "    idcg = ((2.**lv[s:e][argsort][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum()\n",
    "    ndcg = 0\n",
    "    for i in range(sessions_cnt):\n",
    "        tmp = (2.**lv[s:e][permutation[i*osl:(i+1)*osl]-(i*osl)][:min(osl,10)] - 1.)\n",
    "        ndcg += (tmp / (np.log2(2+np.arange(min(osl,10))))).sum() / idcg\n",
    "        \n",
    "    return objective_ins.eval(permutation), ndcg / sessions_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.dlr).max()+2)])\n",
    "exposure2019 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2019.dlr).max()+2)])\n",
    "\n",
    "def learn_one_PPG(metric, qid, alpha, ds, exposure, sessions_cnt):\n",
    "    s, e = ds.dlr[qid:qid+2]\n",
    "\n",
    "    PPG_mat = alpha * np.triu(np.ones((e-s,e-s)), 1)\n",
    "    ref_permutation = ds.y_pred[s:e].argsort()[::-1]\n",
    "    \n",
    "    \n",
    "    output = []\n",
    "    for i in range(sessions_cnt):\n",
    "        b = ref_permutation[PPG._PPG_sample(PPG_mat)] + (i * (e-s))\n",
    "        output.append(b)\n",
    "    output = np.concatenate(output)\n",
    "    \n",
    "    return evaluate_one(metric, qid, ds.lv, ds.g, ds.dlr, output, exposure, sessions_cnt)\n",
    "\n",
    "\n",
    "def learn_one_PL(metric, qid, alpha, ds, exposure, sessions_cnt):\n",
    "    s, e = ds.dlr[qid:qid+2]\n",
    "\n",
    "    log_theta = torch.Tensor(ds.y_pred[s:e]*alpha)\n",
    "    output = []\n",
    "    for i in range(sessions_cnt):\n",
    "        u = torch.distributions.utils.clamp_probs(torch.rand_like(log_theta))\n",
    "        z = PL.to_z(log_theta, u)\n",
    "        b = PL.to_b(z) + (i * (e-s))\n",
    "        output.append(b)\n",
    "    output = np.concatenate(output)\n",
    "    \n",
    "    return evaluate_one(metric, qid, ds.lv, ds.g, ds.dlr, output, exposure, sessions_cnt)\n",
    "\n",
    "\n",
    "def learn_all(metric, ds, exposure, sessions_cnt, learn_fn, alpha):\n",
    "    fairs, ndcgs = [], []\n",
    "    for qid in ds.valids[metric]:\n",
    "        s,e = ds.dlr[qid:qid+2]\n",
    "\n",
    "        fair, ndcg = learn_fn(metric, qid, alpha, ds, exposure, sessions_cnt)\n",
    "\n",
    "        fairs.append(fair)\n",
    "        ndcgs.append(ndcg)\n",
    "    return np.array(fairs), np.array(ndcgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.18310315863628504 0.3914338234658324\n",
      "0.2 0.1796882183899858 0.39059271140253893\n",
      "0.5 0.17085081917689335 0.38692316658387704\n",
      "0.8 0.16300707492068617 0.3768847485398579\n",
      "0.9 0.16285081513862218 0.3664119303960852\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.01, 0.2, 0.5, 0.8, 0.9]:\n",
    "    fair, ndcg = learn_all('EEL', ds2020, exposure2020, 50, learn_one_PPG, alpha)\n",
    "    print(alpha, fair.mean(), ndcg.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.09133724640333857 0.35346327447826786\n",
      "2 0.09220207095782866 0.352870369621071\n",
      "100 0.1060797356092 0.3755233979247745\n",
      "10000 0.18058426305563977 0.3911529929785067\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.01, 2, 100, 10000]:\n",
    "    fair, ndcg = learn_all('EEL', ds2020, exposure2020, 50, learn_one_PL, alpha)\n",
    "    print(alpha, fair.mean(), ndcg.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 1,  8,  5,  9,  3,  2,  6,  0,  7, 10,  4]), tensor([ 1,  5,  2,  4,  6,  3,  0, 10,  9,  7,  8]), tensor([ 2,  0,  9,  5,  1,  8,  6,  3, 10,  4,  7]), tensor([ 1,  3,  5,  6,  9,  0,  7,  4,  8,  2, 10])]\n",
      "[63.468597 64.4381   63.47638  63.202457 62.10881  64.05854  63.718998\n",
      " 62.15418  61.805176 62.561916 62.358166]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  5,  6,  2,  0,  3,  9, 10,  7,  4,  8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validid = 0\n",
    "ds = ds2020\n",
    "qid = ds.valids['EEL'][validid]\n",
    "s, e = ds.dlr[qid:qid+2]\n",
    "log_theta = torch.Tensor(ds.y_pred[s:e]*100)\n",
    "output = []\n",
    "for i in range(4):\n",
    "    u = torch.distributions.utils.clamp_probs(torch.rand_like(log_theta))\n",
    "    z = PL.to_z(log_theta, u)\n",
    "    b = PL.to_b(z)\n",
    "    output.append(b)\n",
    "print(output)\n",
    "print(log_theta.detach().numpy())\n",
    "ds.y_pred[s:e].argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  9,  0,  6,  4,  2,  5,  8,  1,  7, 10,  1,  9, 10,  3,  6,  8,\n",
       "        4,  0,  5,  7,  2,  1,  9, 10,  4,  2,  3,  5,  7,  8,  6,  0,  8,\n",
       "        2,  3,  4,  7, 10,  1,  9,  5,  6,  0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPG_mat = alpha * np.triu(np.ones((e-s,e-s)), 1)\n",
    "ref_permutation = ds.y_pred[s:e].argsort()[::-1]\n",
    "\n",
    "\n",
    "output = []\n",
    "for i in range(sessions_cnt):\n",
    "    b = ref_permutation[PPG._PPG_sample(PPG_mat)] + (i * (e-s))\n",
    "    output.append(b)\n",
    "output = np.concatenate(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import EEL\n",
    "import PL\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "def learn_one_PL(metric, qid, verbose, y_pred, g, dlr, epochs, lr, exposure, grade_levels, samples_cnt, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    \n",
    "    if metric == 'EEL':\n",
    "        objective_ins = EEL.EEL(y_pred = y_pred[s:e], g = g[s:e], dlr = np.array([0,e-s]), exposure=exposure, grade_levels = grade_levels)\n",
    "    else:\n",
    "        objective_ins = DTR.DTR(y_pred = y_pred[s:e], g = g[s:e], dlr = np.array([0,e-s]), exposure=exposure)\n",
    "        \n",
    "    learner = PL.Learner(logits=y_pred[s:e], samples_cnt=samples_cnt, \n",
    "                        objective_ins=objective_ins, sessions_cnt=sessions_cnt)\n",
    "    vals = learner.fit(epochs, lr, verbose=verbose)\n",
    "    return vals\n",
    "\n",
    "def learn_all_PL(metric, y_pred, g, dlr, epochs, lr, exposure, grade_levels, samples_cnt, sessions_cnt):\n",
    "    sorted_docs = []\n",
    "    \n",
    "    for qid in trange(dlr.shape[0] - 1, leave=False):\n",
    "#     for qid in range(dlr.shape[0] - 1):\n",
    "        min_b = learn_one_PL(metric, qid, 0, y_pred, g, dlr, epochs, lr, exposure, grade_levels, samples_cnt, sessions_cnt)\n",
    "        sorted_docs.append(min_b)\n",
    "        \n",
    "\n",
    "    # print(ndcg_dtr(exposure, lv, np.concatenate(y_rerank), dlr, g, query_counts))\n",
    "    return sorted_docs\n",
    "\n",
    "res = learn_all_PL('EEL', ds2020.y_pred, ds2020.g, ds2020.dlr, 50, 0.1, exposure=exposure2020,\n",
    "        grade_levels=5, samples_cnt=32, sessions_cnt=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_one(metric, qid, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    permutation = output_permutation[qid]\n",
    "    lv_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=lv[s:e], g=g[s:e], sorted_docs=lv[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    \n",
    "    if metric == 'EEL':\n",
    "        objective_ins = EEL.EEL(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = 2)\n",
    "    else:\n",
    "        objective_ins = DTR.DTR(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure)\n",
    "        \n",
    "    \n",
    "    osl = e - s\n",
    "    argsort = lv[s:e].argsort()[::-1]\n",
    "    idcg = ((2.**lv[s:e][argsort][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum()\n",
    "    ndcg = 0\n",
    "    for i in range(sessions_cnt):\n",
    "        ndcg += ((2.**lv[s:e][permutation[i*osl:(i+1)*osl]-(i*osl)][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum() / idcg\n",
    "        \n",
    "    return objective_ins.eval(permutation), ndcg / sessions_cnt\n",
    " \n",
    "def evaluate_all(metric, valids, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    eel_res, eer_res, eed_res, ndcgs = [], [], [], []\n",
    "#     for qid in range(dlr.shape[0] - 1):\n",
    "    for qid in valids:\n",
    "        s,e = dlr[qid:qid+2]\n",
    "#         if len(np.unique(g[s:e])) == 1:\n",
    "#             continue\n",
    "        out1, ndcg = evaluate_one(metric, qid, lv, g, dlr, output_permutation, exposure, sessions_cnt)\n",
    "#         eel, eer, eed = out1\n",
    "        eel = out1\n",
    "        eel_res.append(eel)\n",
    "#         eer_res.append(eer)\n",
    "#         eed_res.append(eed)\n",
    "        ndcgs.append(ndcg)\n",
    "    return np.array(eel_res), np.array(ndcgs)\n",
    "#     return np.array(eel_res), np.array(eer_res), np.array(eed_res), np.array(ndcgs)\n",
    "\n",
    "fair, ndcg = evaluate_all('EEL', ds2020.valids['EEL'], ds2020.lv, ds2020.g, ds2020.dlr, res, exposure2020, sessions_cnt=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17196686498345984, 0.3773136188983286)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair.mean(), ndcg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
