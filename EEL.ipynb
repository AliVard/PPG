{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Mmetrics import *\n",
    "\n",
    "import LTR\n",
    "import datautil\n",
    "import permutationgraph\n",
    "import DTR\n",
    "import EEL\n",
    "import PPG\n",
    "import PL\n",
    "\n",
    "def df2ds(df_path):\n",
    "    with open(df_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    ds = df.to_dict(orient='list')\n",
    "    for k in ds:\n",
    "        ds[k] = np.array(ds[k])\n",
    "    ds['dlr'] = np.concatenate([np.zeros(1), np.where(np.diff(ds['qid'])==1)[0]+1, np.array([ds['qid'].shape[0]])]).astype(int)\n",
    "    return type('ltr', (object,), ds)\n",
    "\n",
    "\n",
    "def dict2ds(df_path):\n",
    "    with open(df_path, 'rb') as f:\n",
    "        ds = pickle.load(f)\n",
    "    return type('ltr', (object,), ds)\n",
    "\n",
    "ds2019 = df2ds('LTR2019.df')\n",
    "ds2020 = df2ds('LTR2020.df')\n",
    "sds2019 = dict2ds('s_LTR2019.df')\n",
    "sds2020 = dict2ds('s_LTR2020.df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(ds, percent):\n",
    "    subsample_size = int((ds.dlr.shape[0]-1) * percent)\n",
    "    qids = np.random.choice(np.arange(ds.dlr.shape[0]-1), subsample_size)\n",
    "#     print(qids)\n",
    "    sds = {'lv':[], 'y_pred':[], 'qid':[], 'g':[], 'dlr':[0]}\n",
    "    for qid in qids:\n",
    "        s,e=ds.dlr[qid:qid+2]\n",
    "#         print(s,e)\n",
    "        sds['lv'].append(ds.lv[s:e])\n",
    "        sds['y_pred'].append(ds.y_pred[s:e])\n",
    "        sds['g'].append(ds.g[s:e])\n",
    "        sds['qid'].append(ds.qid[s:e])\n",
    "        sds['dlr'].append(sds['dlr'][-1]+e-s)\n",
    "    for k in ['lv', 'y_pred', 'g', 'qid']:\n",
    "        sds[k] = np.concatenate(sds[k])\n",
    "    sds['dlr'] = np.array(sds['dlr'])\n",
    "    return sds\n",
    "\n",
    "sds2019 = subsample(ds2019, 0.1)\n",
    "sds2020 = subsample(ds2020, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('s_LTR2019.df', 'wb') as f:\n",
    "    pickle.dump(sds2019, f)\n",
    "    \n",
    "with open('s_LTR2020.df', 'wb') as f:\n",
    "    pickle.dump(sds2020, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2019.lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn_one_PPG(qid, verbose, y_pred, g, dlr, epochs, lr, exposure, grade_levels, samples_cnt, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    y_pred_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=y_pred[s:e], g=g[s:e], sorted_docs=y_pred[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    objective_ins = EEL.EEL(y_pred = y_pred_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = grade_levels)\n",
    "    learner = PPG.Learner(  PPG_mat=None, samples_cnt=samples_cnt, \n",
    "                                objective_ins=objective_ins, \n",
    "                                sorted_docs = sorted_docs_s, \n",
    "                                dlr = dlr_s,\n",
    "#                                 intra = np.arange(g_s.shape[0]),\n",
    "                                intra = g_s,\n",
    "                                inter = np.repeat(dlr_s[:-1], np.diff(dlr_s)))\n",
    "    vals = learner.fit(epochs, lr, verbose=verbose)\n",
    "    return vals\n",
    "\n",
    "def learn_all_PPG(y_pred, g, dlr, epochs, lr, exposure, grade_levels, samples_cnt, sessions_cnt):\n",
    "    sorted_docs = []\n",
    "    \n",
    "    for qid in trange(dlr.shape[0] - 1, leave=False):\n",
    "#     for qid in range(dlr.shape[0] - 1):\n",
    "        min_b = learn_one_PPG(qid, 0, y_pred, g, dlr, epochs, lr, exposure, grade_levels, samples_cnt, sessions_cnt)\n",
    "        sorted_docs.append(min_b)\n",
    "        \n",
    "\n",
    "    # print(ndcg_dtr(exposure, lv, np.concatenate(y_rerank), dlr, g, query_counts))\n",
    "    return sorted_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "epochs = 50\n",
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "\n",
    "for qid in range(8):\n",
    "        start = time.time()\n",
    "        learn_one_PPG(qid,0, y_pred2020, ds2020.teg, ds2020.tedlr, epochs, 0.1, exposure=exposure2020,\n",
    "                grade_levels=5, samples_cnt=32, sessions_cnt=20)\n",
    "        print(qid, 'len:', ds2020.tedlr[qid+1]-ds2020.tedlr[qid], 'took:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for qid in range(8):\n",
    "        start = time.time()\n",
    "        learn_one_PPG(qid,0, y_pred2020, ds2020.teg, ds2020.tedlr, epochs, 0.1, exposure=exposure2020,\n",
    "                grade_levels=5, samples_cnt=32, sessions_cnt=20)\n",
    "        print(qid, 'len:', ds2020.tedlr[qid+1]-ds2020.tedlr[qid], 'took:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "res = learn_all_PPG(y_pred2020, ds2020.teg, ds2020.tedlr, epochs, 0.1, exposure=exposure2020,\n",
    "        grade_levels=5, samples_cnt=32, sessions_cnt=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one(metric, qid, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    permutation = output_permutation[qid]\n",
    "    lv_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=lv[s:e], g=g[s:e], sorted_docs=lv[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    \n",
    "    if metric == 'EEL':\n",
    "        objective_ins = EEL.EEL(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = 2)\n",
    "    else:\n",
    "        objective_ins = DTR.DTR(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure)\n",
    "        \n",
    "    \n",
    "    osl = e - s\n",
    "    argsort = lv[s:e].argsort()[::-1]\n",
    "    idcg = ((2.**lv[s:e][argsort][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum()\n",
    "    ndcg = 0\n",
    "    for i in range(sessions_cnt):\n",
    "        ndcg += ((2.**lv[s:e][permutation[i*osl:(i+1)*osl]-(i*osl)][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum() / idcg\n",
    "        \n",
    "    return objective_ins.eval(permutation), ndcg / sessions_cnt\n",
    " \n",
    "def evaluate_all(metric, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    eel_res, eer_res, eed_res, ndcgs = [], [], [], []\n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s,e = dlr[qid:qid+2]\n",
    "        if len(np.unique(g[s:e])) == 1:\n",
    "            continue\n",
    "        out1, ndcg = evaluate_one(metric, qid, lv, g, dlr, output_permutation, exposure, sessions_cnt)\n",
    "#         eel, eer, eed = out1\n",
    "        eel = out1\n",
    "        eel_res.append(eel)\n",
    "#         eer_res.append(eer)\n",
    "#         eed_res.append(eed)\n",
    "        ndcgs.append(ndcg)\n",
    "    return np.array(eel_res), np.array(ndcgs)\n",
    "#     return np.array(eel_res), np.array(eer_res), np.array(eed_res), np.array(ndcgs)\n",
    "\n",
    "def estimated_evaluate_one(qid, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    permutation = output_permutation[qid]\n",
    "    lv_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=lv[s:e], g=g[s:e], sorted_docs=lv[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    objective_ins = EEL.EEL(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = 5)\n",
    "    return objective_ins.eval_detailed(permutation)\n",
    " \n",
    "def estimated_evaluate_all(lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    eel_res, eer_res, eed_res = [], [], []\n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s,e = ds.tedlr[qid:qid+2]\n",
    "        if len(np.unique(g[s:e])) == 1:\n",
    "            continue\n",
    "        eel, eer, eed = estimated_evaluate_one(qid, lv, g, dlr, output_permutation, exposure, sessions_cnt)\n",
    "        eel_res.append(eel)\n",
    "        eer_res.append(eer)\n",
    "        eed_res.append(eed)\n",
    "    return np.array(eel_res), np.array(eer_res), np.array(eed_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def read_results(directory = '/ivi/ilps/personal/avardas/_data/PPG'):\n",
    "    files = os.listdir(directory)\n",
    "    res = {}\n",
    "    for file in files:\n",
    "        if 'pkl' not in file:\n",
    "            continue\n",
    "        with open(f'{directory}/{file}', 'rb') as f:\n",
    "            res[file[:-12]] = pickle.load(f)\n",
    "    return res\n",
    "    \n",
    "res = read_results(directory = '/ivi/ilps/personal/avardas/_data/PPG/test')\n",
    "# res_approx = read_results(directory = '/ivi/ilps/personal/avardas/_data/PPG/test/15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6902d81b9c4002916f5f38e673b775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def get_df_from_results_old(res):\n",
    "    exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "    exposure2019 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2019.tedlr).max()+2)])\n",
    "\n",
    "\n",
    "    dfl = []\n",
    "    for alg in tqdm(res, leave=True):\n",
    "        _res = res[alg]\n",
    "        alg_params = alg.split('_')\n",
    "    #     print(alg, '-'*30)\n",
    "        sessions_cnt = int(alg_params[3])\n",
    "        metric = alg_params[4]\n",
    "        learner = alg_params[1] + '_' + alg_params[0]\n",
    "        samples = int(alg_params[2])\n",
    "\n",
    "        for key in _res:\n",
    "            if '2019' in key:\n",
    "                year = 2019\n",
    "                ds = ds2019\n",
    "                ypred = y_pred2019\n",
    "                exposure = exposure2019\n",
    "            else:\n",
    "                year = 2020\n",
    "                ds = ds2020\n",
    "                ypred = y_pred2020\n",
    "                exposure = exposure2020\n",
    "\n",
    "            lr = key.split('_')[1]\n",
    "            eel_res, ndcg = evaluate_all(metric, ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=sessions_cnt)\n",
    "            dfl.append({'year':year, 'metric':metric, 'learner':learner, \n",
    "            'samples':samples, 'sessions':sessions_cnt, 'lr':lr, 'Fairness':eel_res.mean(), 'NDCG':ndcg.mean()})\n",
    "\n",
    "    return pd.DataFrame(dfl)\n",
    "\n",
    "\n",
    "\n",
    "def get_df_from_results(res):\n",
    "    exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.dlr).max()+2)])\n",
    "    exposure2019 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2019.dlr).max()+2)])\n",
    "\n",
    "\n",
    "    dfl = []\n",
    "    for alg in tqdm(res, leave=True):\n",
    "        _res = res[alg]\n",
    "        alg_params = alg.split('_')\n",
    "    #     print(alg, '-'*30)\n",
    "        sessions_cnt = int(alg_params[2])\n",
    "        metric = alg_params[3]\n",
    "        learner = alg_params[1] + '_' + alg_params[0]\n",
    "\n",
    "        for key in _res:\n",
    "            if '2019' in key:\n",
    "                year = 2019\n",
    "                ds = ds2019\n",
    "                exposure = exposure2019\n",
    "            else:\n",
    "                year = 2020\n",
    "                ds = ds2020\n",
    "                exposure = exposure2020\n",
    "\n",
    "            lr = key.split('_')[1]\n",
    "            samples = int(key.split('_')[2])\n",
    "            eel_res, ndcg = evaluate_all(metric, ds.lv, ds.g, ds.dlr, _res[key], exposure, sessions_cnt=sessions_cnt)\n",
    "            dfl.append({'year':year, 'metric':metric, 'learner':learner, \n",
    "            'samples':samples, 'sessions':sessions_cnt, 'lr':lr, 'Fairness':eel_res.mean(), 'NDCG':ndcg.mean()})\n",
    "\n",
    "    return pd.DataFrame(dfl)\n",
    "\n",
    "\n",
    "df = get_df_from_results(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>metric</th>\n",
       "      <th>learner</th>\n",
       "      <th>samples</th>\n",
       "      <th>sessions</th>\n",
       "      <th>lr</th>\n",
       "      <th>Fairness</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.603934</td>\n",
       "      <td>0.761296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.564656</td>\n",
       "      <td>0.793540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.565660</td>\n",
       "      <td>0.764338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.182406</td>\n",
       "      <td>0.348552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.117481</td>\n",
       "      <td>0.391401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.118287</td>\n",
       "      <td>0.401981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.592670</td>\n",
       "      <td>0.763790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.559839</td>\n",
       "      <td>0.792458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.558078</td>\n",
       "      <td>0.753415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.132365</td>\n",
       "      <td>0.380054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.120571</td>\n",
       "      <td>0.386127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.118647</td>\n",
       "      <td>0.347271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.578781</td>\n",
       "      <td>0.755413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.558305</td>\n",
       "      <td>0.790491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.556592</td>\n",
       "      <td>0.752772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.120953</td>\n",
       "      <td>0.349925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.114650</td>\n",
       "      <td>0.392826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.118814</td>\n",
       "      <td>0.336569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.564721</td>\n",
       "      <td>0.758301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.557193</td>\n",
       "      <td>0.788515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.556893</td>\n",
       "      <td>0.751263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.126183</td>\n",
       "      <td>0.359586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.115133</td>\n",
       "      <td>0.390112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.117605</td>\n",
       "      <td>0.350449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.556187</td>\n",
       "      <td>0.756195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.556561</td>\n",
       "      <td>0.787921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.556592</td>\n",
       "      <td>0.751139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.133879</td>\n",
       "      <td>0.353166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.115964</td>\n",
       "      <td>0.386372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_nointra</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.115488</td>\n",
       "      <td>0.355667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.562652</td>\n",
       "      <td>0.757301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PL_nointra</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.111594</td>\n",
       "      <td>0.354929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020</td>\n",
       "      <td>DTR</td>\n",
       "      <td>PPG_intra</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.106316</td>\n",
       "      <td>0.388263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year metric      learner  samples  sessions    lr  Fairness      NDCG\n",
       "23  2019    DTR   PL_nointra       32         1  0.01  0.603934  0.761296\n",
       "15  2019    DTR    PPG_intra       32         1  0.01  0.564656  0.793540\n",
       "11  2019    DTR  PPG_nointra       32         1  0.01  0.565660  0.764338\n",
       "22  2020    DTR   PL_nointra        8         1  0.01  1.182406  0.348552\n",
       "14  2020    DTR    PPG_intra       32         1  0.01  1.117481  0.391401\n",
       "10  2020    DTR  PPG_nointra       32         1  0.01  1.118287  0.401981\n",
       "27  2019    DTR   PL_nointra        4         2  0.01  0.592670  0.763790\n",
       "3   2019    DTR    PPG_intra       32         2  0.01  0.559839  0.792458\n",
       "1   2019    DTR  PPG_nointra       16         2  0.01  0.558078  0.753415\n",
       "26  2020    DTR   PL_nointra        4         2  0.01  1.132365  0.380054\n",
       "2   2020    DTR    PPG_intra       32         2  0.01  1.120571  0.386127\n",
       "0   2020    DTR  PPG_nointra       32         2  0.01  1.118647  0.347271\n",
       "5   2019    DTR   PL_nointra       16         4  0.01  0.578781  0.755413\n",
       "30  2019    DTR    PPG_intra       16         4  0.01  0.558305  0.790491\n",
       "32  2019    DTR  PPG_nointra       32         4  0.01  0.556592  0.752772\n",
       "4   2020    DTR   PL_nointra       32         4  0.01  1.120953  0.349925\n",
       "29  2020    DTR    PPG_intra       32         4  0.01  1.114650  0.392826\n",
       "31  2020    DTR  PPG_nointra       32         4  0.01  1.118814  0.336569\n",
       "13  2019    DTR   PL_nointra       16         8  0.01  0.564721  0.758301\n",
       "25  2019    DTR    PPG_intra       32         8  0.01  0.557193  0.788515\n",
       "21  2019    DTR  PPG_nointra       32         8  0.01  0.556893  0.751263\n",
       "12  2020    DTR   PL_nointra       16         8  0.01  1.126183  0.359586\n",
       "24  2020    DTR    PPG_intra       32         8  0.01  1.115133  0.390112\n",
       "20  2020    DTR  PPG_nointra       32         8  0.01  1.117605  0.350449\n",
       "7   2019    DTR   PL_nointra        4        16  0.01  0.556187  0.756195\n",
       "9   2019    DTR    PPG_intra       32        16  0.01  0.556561  0.787921\n",
       "19  2019    DTR  PPG_nointra       32        16  0.01  0.556592  0.751139\n",
       "6   2020    DTR   PL_nointra       16        16  0.01  1.133879  0.353166\n",
       "8   2020    DTR    PPG_intra       32        16  0.01  1.115964  0.386372\n",
       "18  2020    DTR  PPG_nointra       32        16  0.01  1.115488  0.355667\n",
       "17  2019    DTR   PL_nointra        8        32  0.01  0.562652  0.757301\n",
       "16  2020    DTR   PL_nointra        8        32  0.01  1.111594  0.354929\n",
       "28  2020    DTR    PPG_intra       16        32  0.01  1.106316  0.388263"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['metric', 'sessions', 'year', 'learner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Fairness, NDCG, learner, lr, samples, sessions]\n",
      "Index: []\n",
      "------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [Fairness, NDCG, learner, lr, samples, sessions]\n",
      "Index: []\n",
      "------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [Fairness, NDCG, learner, lr, samples, sessions]\n",
      "Index: []\n",
      "------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [Fairness, NDCG, learner, lr, samples, sessions]\n",
      "Index: []\n",
      "------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [Fairness, NDCG, learner, lr, samples, sessions]\n",
      "Index: []\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def refine_df(df, sessions, metric, year):\n",
    "    return df.loc[(df.sessions==sessions) & (df.metric==metric) & (df.year == year), sorted(list(set(df.columns)-set(('metric', 'year'))))].sort_values(by=['samples', 'lr', 'learner'])\n",
    "\n",
    "# df_joint = df.merge(df_approx, on=['learner', 'lr', 'metric', 'samples', 'sessions', 'year'], how='left')\n",
    "for sessions in [1,2,4,8,16]:\n",
    "    print(refine_df(df, sessions, 'EEL', 2019).head(100))\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "exposure2019 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2019.tedlr).max()+2)])\n",
    "\n",
    "\n",
    "for alg in res:\n",
    "    _res = res[alg]\n",
    "    print(alg, '-'*30)\n",
    "    sessions_cnt = int(alg.split('_')[3])\n",
    "    metric = alg.split('_')[4]\n",
    "    for key in _res:\n",
    "        if '2019' in key:\n",
    "            ds = ds2019\n",
    "            ypred = y_pred2019\n",
    "            exposure = exposure2019\n",
    "        else:\n",
    "            ds = ds2020\n",
    "            ypred = y_pred2020\n",
    "            exposure = exposure2020\n",
    "            \n",
    "#         eel_res, eer_res, eed_res, ndcg = evaluate_all(ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=sessions_cnt)\n",
    "        eel_res, ndcg = evaluate_all(metric, ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=sessions_cnt)\n",
    "#         es_eel_res, es_eer_res, es_eed_res = estimated_evaluate_all(ypred, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=20)\n",
    "    \n",
    "        print(f'{key}', eel_res.mean(), '(', ndcg.mean(), ')')\n",
    "#         print(f'{key}', eel_res.mean(), '(', es_eel_res.mean(), ')')\n",
    "#         print(f'\\t', ndcg.mean())\n",
    "#         print(f'\\t', eer_res.mean(), '(', es_eer_res.mean(), ')')\n",
    "#         print(f'\\t', eed_res.mean(), '(', es_eed_res.mean(), ')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(qid, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    permutation = output_permutation[qid]\n",
    "    lv_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=lv[s:e], g=g[s:e], sorted_docs=lv[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    objective_ins = EEL.EEL(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = 2)\n",
    "    \n",
    "    osl = e - s\n",
    "    argsort = lv[s:e].argsort()[::-1]\n",
    "    print(argsort)\n",
    "    print(lv[s:e])\n",
    "    idcg = ((2.**lv[s:e][argsort][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum()\n",
    "    print('idcg:', idcg)\n",
    "    ndcg = 0\n",
    "    for i in range(sessions_cnt):\n",
    "        dcg = ((2.**lv[s:e][permutation[i*osl:(i+1)*osl]-(i*osl)][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum()\n",
    "        print('dcg:', dcg)\n",
    "        ndcg += dcg / idcg\n",
    "        \n",
    "    return objective_ins.eval_detailed(permutation), ndcg / sessions_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds2019\n",
    "# exposure = exposure2020\n",
    "# _res = res['PPG']\n",
    "# key = '2019_0.01'\n",
    "test(1,ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eel_res, eer_res, eed_res, ndcg = evaluate_all(ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
