{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Mmetrics import *\n",
    "\n",
    "import LTR\n",
    "import datautil\n",
    "import permutationgraph\n",
    "import DTR\n",
    "import EEL\n",
    "import PPG\n",
    "import PL\n",
    "\n",
    "def df2ds(df_path):\n",
    "    with open(df_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    ds = df.to_dict(orient='list')\n",
    "    for k in ds:\n",
    "        ds[k] = np.array(ds[k])\n",
    "    ds['dlr'] = np.concatenate([np.zeros(1), np.where(np.diff(ds['qid'])==1)[0]+1, np.array([ds['qid'].shape[0]])]).astype(int)\n",
    "    return type('ltr', (object,), ds)\n",
    "\n",
    "\n",
    "def dict2ds(df_path):\n",
    "    with open(df_path, 'rb') as f:\n",
    "        ds = pickle.load(f)\n",
    "    return type('ltr', (object,), ds)\n",
    "\n",
    "ds2019 = df2ds('LTR2019.df')\n",
    "ds2020 = df2ds('LTR2020.df')\n",
    "sds2019 = dict2ds('s_LTR2019.df')\n",
    "sds2020 = dict2ds('s_LTR2020.df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_y(name):\n",
    "    ds = df2ds(f'LTR{name}.df')\n",
    "    for qid in range(ds.dlr.shape[0] - 1):\n",
    "        s, e = ds.dlr[qid: qid+2]\n",
    "        y = EEL.linspan(ds.y_pred[s:e], 5)\n",
    "        ds.y_pred[s:e] = y\n",
    "    with open(f'nLTR{name}.df', 'wb') as f:\n",
    "        df = pd.DataFrame({'qid':list(ds.qid), 'g':list(ds.g), 'lv':list(ds.lv), 'y_pred':list(ds.y_pred)})\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "normalize_y('2019')\n",
    "normalize_y('2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_y_MSLR():\n",
    "    with open('p_MSLR_qs.df', 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    for qid in range(df['dlr'].shape[0] - 1):\n",
    "        s, e = df['dlr'][qid: qid+2]\n",
    "        y = EEL.linspan(df['y_pred'][s:e], 5)\n",
    "        df['y_pred'][s:e] = y\n",
    "    with open(f'nLTRMSLR_dict.df', 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "normalize_y_MSLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1733,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = dict2ds(f'p_MSLR_qs.df')\n",
    "ds.dlr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1733,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2 = dict2ds(f'nLTRMSLR_dict.df')\n",
    "ds2.dlr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6111 6111\n"
     ]
    }
   ],
   "source": [
    "qid = ds.qid\n",
    "qid2 = ds2.qid\n",
    "print(qid.max(), qid2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(ds, percent):\n",
    "    subsample_size = int((ds.dlr.shape[0]-1) * percent)\n",
    "    qids = np.random.choice(np.arange(ds.dlr.shape[0]-1), subsample_size)\n",
    "#     print(qids)\n",
    "    sds = {'lv':[], 'y_pred':[], 'qid':[], 'g':[], 'dlr':[0]}\n",
    "    for qid in qids:\n",
    "        s,e=ds.dlr[qid:qid+2]\n",
    "#         print(s,e)\n",
    "        sds['lv'].append(ds.lv[s:e])\n",
    "        sds['y_pred'].append(ds.y_pred[s:e])\n",
    "        sds['g'].append(ds.g[s:e])\n",
    "        sds['qid'].append(ds.qid[s:e])\n",
    "        sds['dlr'].append(sds['dlr'][-1]+e-s)\n",
    "    for k in ['lv', 'y_pred', 'g', 'qid']:\n",
    "        sds[k] = np.concatenate(sds[k])\n",
    "    sds['dlr'] = np.array(sds['dlr'])\n",
    "    return sds\n",
    "\n",
    "sds2019 = subsample(ds2019, 0.1)\n",
    "sds2020 = subsample(ds2020, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('s_LTR2019.df', 'wb') as f:\n",
    "    pickle.dump(sds2019, f)\n",
    "    \n",
    "with open('s_LTR2020.df', 'wb') as f:\n",
    "    pickle.dump(sds2020, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2019.lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn_one_PPG(qid, verbose, y_pred, g, dlr, epochs, lr, exposure, grade_levels, samples_cnt, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    y_pred_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=y_pred[s:e], g=g[s:e], sorted_docs=y_pred[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    objective_ins = EEL.EEL(y_pred = y_pred_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = grade_levels)\n",
    "    learner = PPG.Learner(  PPG_mat=None, samples_cnt=samples_cnt, \n",
    "                                objective_ins=objective_ins, \n",
    "                                sorted_docs = sorted_docs_s, \n",
    "                                dlr = dlr_s,\n",
    "#                                 intra = np.arange(g_s.shape[0]),\n",
    "                                intra = g_s,\n",
    "                                inter = np.repeat(dlr_s[:-1], np.diff(dlr_s)))\n",
    "    vals = learner.fit(epochs, lr, verbose=verbose)\n",
    "    return vals\n",
    "\n",
    "def learn_all_PPG(y_pred, g, dlr, epochs, lr, exposure, grade_levels, samples_cnt, sessions_cnt):\n",
    "    sorted_docs = []\n",
    "    \n",
    "    for qid in trange(dlr.shape[0] - 1, leave=False):\n",
    "#     for qid in range(dlr.shape[0] - 1):\n",
    "        min_b = learn_one_PPG(qid, 0, y_pred, g, dlr, epochs, lr, exposure, grade_levels, samples_cnt, sessions_cnt)\n",
    "        sorted_docs.append(min_b)\n",
    "        \n",
    "\n",
    "    # print(ndcg_dtr(exposure, lv, np.concatenate(y_rerank), dlr, g, query_counts))\n",
    "    return sorted_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "epochs = 50\n",
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "\n",
    "for qid in range(8):\n",
    "        start = time.time()\n",
    "        learn_one_PPG(qid,0, y_pred2020, ds2020.teg, ds2020.tedlr, epochs, 0.1, exposure=exposure2020,\n",
    "                grade_levels=5, samples_cnt=32, sessions_cnt=20)\n",
    "        print(qid, 'len:', ds2020.tedlr[qid+1]-ds2020.tedlr[qid], 'took:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for qid in range(8):\n",
    "        start = time.time()\n",
    "        learn_one_PPG(qid,0, y_pred2020, ds2020.teg, ds2020.tedlr, epochs, 0.1, exposure=exposure2020,\n",
    "                grade_levels=5, samples_cnt=32, sessions_cnt=20)\n",
    "        print(qid, 'len:', ds2020.tedlr[qid+1]-ds2020.tedlr[qid], 'took:', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "res = learn_all_PPG(y_pred2020, ds2020.teg, ds2020.tedlr, epochs, 0.1, exposure=exposure2020,\n",
    "        grade_levels=5, samples_cnt=32, sessions_cnt=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one(metric, qid, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    permutation = output_permutation[qid]\n",
    "    lv_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=lv[s:e], g=g[s:e], sorted_docs=lv[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    \n",
    "    if metric == 'EEL':\n",
    "        objective_ins = EEL.EEL(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = 2)\n",
    "    else:\n",
    "        objective_ins = DTR.DTR(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure)\n",
    "        \n",
    "    \n",
    "    osl = e - s\n",
    "    argsort = lv[s:e].argsort()[::-1]\n",
    "    idcg = ((2.**lv[s:e][argsort][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum()\n",
    "    ndcg = 0\n",
    "    for i in range(sessions_cnt):\n",
    "        ndcg += ((2.**lv[s:e][permutation[i*osl:(i+1)*osl]-(i*osl)][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum() / idcg\n",
    "        \n",
    "    return objective_ins.eval(permutation), ndcg / sessions_cnt\n",
    " \n",
    "def evaluate_all(metric, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    eel_res, eer_res, eed_res, ndcgs = [], [], [], []\n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s,e = dlr[qid:qid+2]\n",
    "        if len(np.unique(g[s:e])) == 1:\n",
    "            continue\n",
    "        out1, ndcg = evaluate_one(metric, qid, lv, g, dlr, output_permutation, exposure, sessions_cnt)\n",
    "#         eel, eer, eed = out1\n",
    "        eel = out1\n",
    "        eel_res.append(eel)\n",
    "#         eer_res.append(eer)\n",
    "#         eed_res.append(eed)\n",
    "        ndcgs.append(ndcg)\n",
    "    return np.array(eel_res), np.array(ndcgs)\n",
    "#     return np.array(eel_res), np.array(eer_res), np.array(eed_res), np.array(ndcgs)\n",
    "\n",
    "def estimated_evaluate_one(qid, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    permutation = output_permutation[qid]\n",
    "    lv_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=lv[s:e], g=g[s:e], sorted_docs=lv[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    objective_ins = EEL.EEL(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = 5)\n",
    "    return objective_ins.eval_detailed(permutation)\n",
    " \n",
    "def estimated_evaluate_all(lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    eel_res, eer_res, eed_res = [], [], []\n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s,e = ds.tedlr[qid:qid+2]\n",
    "        if len(np.unique(g[s:e])) == 1:\n",
    "            continue\n",
    "        eel, eer, eed = estimated_evaluate_one(qid, lv, g, dlr, output_permutation, exposure, sessions_cnt)\n",
    "        eel_res.append(eel)\n",
    "        eer_res.append(eer)\n",
    "        eed_res.append(eed)\n",
    "    return np.array(eel_res), np.array(eer_res), np.array(eed_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def read_results(directory = '/ivi/ilps/personal/avardas/_data/PPG'):\n",
    "    files = os.listdir(directory)\n",
    "    res = {}\n",
    "    for file in files:\n",
    "        if 'pkl' not in file:\n",
    "            continue\n",
    "        with open(f'{directory}/{file}', 'rb') as f:\n",
    "            res[file[:-12]] = pickle.load(f)\n",
    "    return res\n",
    "    \n",
    "res = read_results(directory = '/ivi/ilps/personal/avardas/_data/PPG/test')\n",
    "# res_approx = read_results(directory = '/ivi/ilps/personal/avardas/_data/PPG/test/15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0145704b6a3d4650900c7d24ebd6a022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=33.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def get_df_from_results_old(res):\n",
    "    exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "    exposure2019 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2019.tedlr).max()+2)])\n",
    "\n",
    "\n",
    "    dfl = []\n",
    "    for alg in tqdm(res, leave=True):\n",
    "        _res = res[alg]\n",
    "        alg_params = alg.split('_')\n",
    "    #     print(alg, '-'*30)\n",
    "        sessions_cnt = int(alg_params[3])\n",
    "        metric = alg_params[4]\n",
    "        learner = alg_params[1] + '_' + alg_params[0]\n",
    "        samples = int(alg_params[2])\n",
    "\n",
    "        for key in _res:\n",
    "            if '2019' in key:\n",
    "                year = 2019\n",
    "                ds = ds2019\n",
    "                ypred = y_pred2019\n",
    "                exposure = exposure2019\n",
    "            else:\n",
    "                year = 2020\n",
    "                ds = ds2020\n",
    "                ypred = y_pred2020\n",
    "                exposure = exposure2020\n",
    "\n",
    "            lr = key.split('_')[1]\n",
    "            eel_res, ndcg = evaluate_all(metric, ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=sessions_cnt)\n",
    "            dfl.append({'year':year, 'metric':metric, 'learner':learner, \n",
    "            'samples':samples, 'sessions':sessions_cnt, 'lr':lr, 'Fairness':eel_res.mean(), 'NDCG':ndcg.mean()})\n",
    "\n",
    "    return pd.DataFrame(dfl)\n",
    "\n",
    "\n",
    "\n",
    "def get_df_from_results(res):\n",
    "    exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.dlr).max()+2)])\n",
    "    exposure2019 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2019.dlr).max()+2)])\n",
    "\n",
    "\n",
    "    dfl = []\n",
    "    for alg in tqdm(res, leave=True):\n",
    "        _res = res[alg]\n",
    "        alg_params = alg.split('_')\n",
    "    #     print(alg, '-'*30)\n",
    "        sessions_cnt = int(alg_params[2])\n",
    "        metric = alg_params[3]\n",
    "        learner = alg_params[1] + '_' + alg_params[0]\n",
    "\n",
    "        for key in _res:\n",
    "            if '2019' in key:\n",
    "                year = 2019\n",
    "                ds = ds2019\n",
    "                exposure = exposure2019\n",
    "            else:\n",
    "                year = 2020\n",
    "                ds = ds2020\n",
    "                exposure = exposure2020\n",
    "\n",
    "            lr = key.split('_')[1]\n",
    "            samples = int(key.split('_')[2])\n",
    "            eel_res, ndcg = evaluate_all(metric, ds.lv, ds.g, ds.dlr, _res[key], exposure, sessions_cnt=sessions_cnt)\n",
    "            dfl.append({'year':year, 'metric':metric, 'learner':learner, \n",
    "            'samples':samples, 'sessions':sessions_cnt, 'lr':lr, 'Fairness':eel_res.mean(), 'NDCG':ndcg.mean()})\n",
    "\n",
    "    return pd.DataFrame(dfl)\n",
    "\n",
    "\n",
    "df = get_df_from_results(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year metric      learner  samples  sessions    lr  Fairness      NDCG\n",
      "48  2019    DTR   PL_nointra       32         1  0.01  0.603934  0.761296\n",
      "29  2019    DTR    PPG_intra       32         1  0.01  0.564656  0.793540\n",
      "25  2019    DTR  PPG_nointra       32         1  0.01  0.565660  0.764338\n",
      "47  2020    DTR   PL_nointra        8         1  0.01  1.182406  0.348552\n",
      "28  2020    DTR    PPG_intra       32         1  0.01  1.117481  0.391401\n",
      "..   ...    ...          ...      ...       ...   ...       ...       ...\n",
      "4   2020    EEL   PL_nointra       32        16  0.01  0.096880  0.356623\n",
      "30  2020    EEL    PPG_intra       16        16  0.01  0.150840  0.389316\n",
      "34  2020    EEL  PPG_nointra       32        16  0.01  0.109646  0.357069\n",
      "33  2019    EEL   PL_nointra       32        32  0.01  0.028359  0.757571\n",
      "32  2020    EEL   PL_nointra       32        32  0.01  0.101208  0.358215\n",
      "\n",
      "[65 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.sort_values(by=['metric', 'sessions', 'year', 'learner']).head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fairness      NDCG      learner    lr  samples  sessions\n",
      "38  0.059956  0.752894   PL_nointra  0.01       32         1\n",
      "21  0.046645  0.799777    PPG_intra  0.01        8         1\n",
      "17  0.043765  0.766477  PPG_nointra  0.01        4         1\n",
      "60  0.044002  0.748923   PL_nointra  0.01       16         2\n",
      "15  0.044671  0.797066    PPG_intra  0.01        8         2\n",
      "11  0.043007  0.755952  PPG_nointra  0.01        8         2\n",
      "1   0.036602  0.758194   PL_nointra  0.01       32         4\n",
      "56  0.040269  0.794528    PPG_intra  0.01        4         4\n",
      "58  0.036585  0.751694  PPG_nointra  0.01        4         4\n",
      "19  0.032408  0.756587   PL_nointra  0.01       16         8\n",
      "40  0.038225  0.792841    PPG_intra  0.01        4         8\n",
      "36  0.035488  0.756497  PPG_nointra  0.01        8         8\n",
      "5   0.029446  0.760406   PL_nointra  0.01       32        16\n",
      "31  0.036070  0.792974    PPG_intra  0.01        4        16\n",
      "33  0.028359  0.757571   PL_nointra  0.01       32        32\n",
      "    Fairness      NDCG      learner    lr  samples  sessions\n",
      "37  0.206325  0.342487   PL_nointra  0.01        8         1\n",
      "20  0.158223  0.394471    PPG_intra  0.01       16         1\n",
      "16  0.151096  0.360053  PPG_nointra  0.01        8         1\n",
      "59  0.143524  0.358343   PL_nointra  0.01       32         2\n",
      "14  0.157207  0.390984    PPG_intra  0.01       16         2\n",
      "10  0.140879  0.359980  PPG_nointra  0.01        8         2\n",
      "0   0.124247  0.357650   PL_nointra  0.01       32         4\n",
      "55  0.155163  0.392798    PPG_intra  0.01        8         4\n",
      "57  0.125704  0.349593  PPG_nointra  0.01        8         4\n",
      "18  0.104059  0.361356   PL_nointra  0.01       32         8\n",
      "39  0.155126  0.386744    PPG_intra  0.01       32         8\n",
      "35  0.100740  0.357834  PPG_nointra  0.01        4         8\n",
      "4   0.096880  0.356623   PL_nointra  0.01       32        16\n",
      "30  0.150840  0.389316    PPG_intra  0.01       16        16\n",
      "34  0.109646  0.357069  PPG_nointra  0.01       32        16\n",
      "32  0.101208  0.358215   PL_nointra  0.01       32        32\n",
      "    Fairness      NDCG      learner    lr  samples  sessions\n",
      "48  0.603934  0.761296   PL_nointra  0.01       32         1\n",
      "29  0.564656  0.793540    PPG_intra  0.01       32         1\n",
      "25  0.565660  0.764338  PPG_nointra  0.01       32         1\n",
      "52  0.592670  0.763790   PL_nointra  0.01        4         2\n",
      "7   0.559839  0.792458    PPG_intra  0.01       32         2\n",
      "3   0.558078  0.753415  PPG_nointra  0.01       16         2\n",
      "9   0.578781  0.755413   PL_nointra  0.01       16         4\n",
      "62  0.558305  0.790491    PPG_intra  0.01       16         4\n",
      "64  0.556592  0.752772  PPG_nointra  0.01       32         4\n",
      "27  0.564721  0.758301   PL_nointra  0.01       16         8\n",
      "50  0.557193  0.788515    PPG_intra  0.01       32         8\n",
      "46  0.556893  0.751263  PPG_nointra  0.01       32         8\n",
      "13  0.556187  0.756195   PL_nointra  0.01        4        16\n",
      "23  0.556561  0.787921    PPG_intra  0.01       32        16\n",
      "44  0.556592  0.751139  PPG_nointra  0.01       32        16\n",
      "42  0.562652  0.757301   PL_nointra  0.01        8        32\n",
      "54  0.556820  0.788091    PPG_intra  0.01       32        32\n",
      "    Fairness      NDCG      learner    lr  samples  sessions\n",
      "47  1.182406  0.348552   PL_nointra  0.01        8         1\n",
      "28  1.117481  0.391401    PPG_intra  0.01       32         1\n",
      "24  1.118287  0.401981  PPG_nointra  0.01       32         1\n",
      "51  1.132365  0.380054   PL_nointra  0.01        4         2\n",
      "6   1.120571  0.386127    PPG_intra  0.01       32         2\n",
      "2   1.118647  0.347271  PPG_nointra  0.01       32         2\n",
      "8   1.120953  0.349925   PL_nointra  0.01       32         4\n",
      "61  1.114650  0.392826    PPG_intra  0.01       32         4\n",
      "63  1.118814  0.336569  PPG_nointra  0.01       32         4\n",
      "26  1.126183  0.359586   PL_nointra  0.01       16         8\n",
      "49  1.115133  0.390112    PPG_intra  0.01       32         8\n",
      "45  1.117605  0.350449  PPG_nointra  0.01       32         8\n",
      "12  1.133879  0.353166   PL_nointra  0.01       16        16\n",
      "22  1.115964  0.386372    PPG_intra  0.01       32        16\n",
      "43  1.115488  0.355667  PPG_nointra  0.01       32        16\n",
      "41  1.111594  0.354929   PL_nointra  0.01        8        32\n",
      "53  1.106316  0.388263    PPG_intra  0.01       16        32\n"
     ]
    }
   ],
   "source": [
    "def refine_df(df, metric, year):\n",
    "    return df.loc[(df.metric==metric) & (df.year == year), sorted(list(set(df.columns)-set(('metric', 'year'))))].sort_values(by=['sessions', 'learner'])\n",
    "\n",
    "print()\n",
    "print(refine_df(df, 'EEL', 2019).head(100))\n",
    "print(refine_df(df, 'EEL', 2020).head(100))\n",
    "print(refine_df(df, 'DTR', 2019).head(100))\n",
    "print(refine_df(df, 'DTR', 2020).head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "exposure2019 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2019.tedlr).max()+2)])\n",
    "\n",
    "\n",
    "for alg in res:\n",
    "    _res = res[alg]\n",
    "    print(alg, '-'*30)\n",
    "    sessions_cnt = int(alg.split('_')[3])\n",
    "    metric = alg.split('_')[4]\n",
    "    for key in _res:\n",
    "        if '2019' in key:\n",
    "            ds = ds2019\n",
    "            ypred = y_pred2019\n",
    "            exposure = exposure2019\n",
    "        else:\n",
    "            ds = ds2020\n",
    "            ypred = y_pred2020\n",
    "            exposure = exposure2020\n",
    "            \n",
    "#         eel_res, eer_res, eed_res, ndcg = evaluate_all(ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=sessions_cnt)\n",
    "        eel_res, ndcg = evaluate_all(metric, ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=sessions_cnt)\n",
    "#         es_eel_res, es_eer_res, es_eed_res = estimated_evaluate_all(ypred, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=20)\n",
    "    \n",
    "        print(f'{key}', eel_res.mean(), '(', ndcg.mean(), ')')\n",
    "#         print(f'{key}', eel_res.mean(), '(', es_eel_res.mean(), ')')\n",
    "#         print(f'\\t', ndcg.mean())\n",
    "#         print(f'\\t', eer_res.mean(), '(', es_eer_res.mean(), ')')\n",
    "#         print(f'\\t', eed_res.mean(), '(', es_eed_res.mean(), ')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(qid, lv, g, dlr, output_permutation, exposure, sessions_cnt):\n",
    "    s, e = dlr[qid:qid+2]\n",
    "    permutation = output_permutation[qid]\n",
    "    lv_s, g_s, sorted_docs_s, dlr_s = \\\n",
    "        EEL.copy_sessions(y=lv[s:e], g=g[s:e], sorted_docs=lv[s:e].argsort()[::-1], sessions=sessions_cnt)\n",
    "    objective_ins = EEL.EEL(y_pred = lv_s, g = g_s, dlr = dlr_s, exposure=exposure, grade_levels = 2)\n",
    "    \n",
    "    osl = e - s\n",
    "    argsort = lv[s:e].argsort()[::-1]\n",
    "    print(argsort)\n",
    "    print(lv[s:e])\n",
    "    idcg = ((2.**lv[s:e][argsort][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum()\n",
    "    print('idcg:', idcg)\n",
    "    ndcg = 0\n",
    "    for i in range(sessions_cnt):\n",
    "        dcg = ((2.**lv[s:e][permutation[i*osl:(i+1)*osl]-(i*osl)][:min(osl,10)] - 1.) / (np.log2(2+np.arange(min(osl,10))))).sum()\n",
    "        print('dcg:', dcg)\n",
    "        ndcg += dcg / idcg\n",
    "        \n",
    "    return objective_ins.eval_detailed(permutation), ndcg / sessions_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds2019\n",
    "# exposure = exposure2020\n",
    "# _res = res['PPG']\n",
    "# key = '2019_0.01'\n",
    "test(1,ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eel_res, eer_res, eed_res, ndcg = evaluate_all(ds.telv, ds.teg, ds.tedlr, _res[key], exposure, sessions_cnt=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
