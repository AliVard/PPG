{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "train: 4694 docs, 200 queries.\n",
      "test: 4677 docs, 200 queries.\n",
      "25 features\n",
      "un-normalized train: 70.080336425764 <101.65279842486342>\n",
      "un-normalized test: 75.07174581020573 <156.60887376760795>\n",
      "normalized train: 5.180490685311132e-07 <0.7804636401064724>\n",
      "normalized test: 1.3643793263153821e-06 <0.7887188357739844>\n",
      "train: 2672 docs, 632 queries.\n",
      "test: 4298 docs, 635 queries.\n",
      "25 features\n",
      "un-normalized train: 100.59542148518399 <112.00393006016057>\n",
      "un-normalized test: 107.18769941395159 <118.13138269196044>\n",
      "normalized train: 7.412363746142352e-08 <0.7544854415648509>\n",
      "normalized test: -2.8577670556600825e-08 <0.7641385980060638>\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Mmetrics import *\n",
    "\n",
    "import LTR\n",
    "import datautil\n",
    "import permutationgraph\n",
    "import DTR\n",
    "import EEL\n",
    "import PPG\n",
    "import PL\n",
    "\n",
    "ds2020, _ = datautil.load_data(2020, verbose=True)\n",
    "ds2019, _ = datautil.load_data(2019, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a LTR model (MSE)\n",
    "\n",
    "Set `y_pred` using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 -> loss: 0.052073169499635696, train ndcg@10: 0.3503035268320601, ndcg@10: 0.3876295792750259\n",
      "epoch 1 -> loss: 0.01319053117185831, train ndcg@10: 0.35274867528084786, ndcg@10: 0.4052124510311721\n",
      "epoch 2 -> loss: 0.010403155349195004, train ndcg@10: 0.3584947545414017, ndcg@10: 0.3978479170063658\n",
      "epoch 3 -> loss: 0.009867612272500992, train ndcg@10: 0.3557424574748109, ndcg@10: 0.382260882004556\n",
      "epoch 4 -> loss: 0.009421426802873611, train ndcg@10: 0.3526311535996758, ndcg@10: 0.39615375900304395\n",
      "epoch 5 -> loss: 0.008984922431409359, train ndcg@10: 0.35874285320080174, ndcg@10: 0.38391187753334166\n",
      "epoch 6 -> loss: 0.008523018099367619, train ndcg@10: 0.35984124128292594, ndcg@10: 0.46096574867997964\n",
      "epoch 7 -> loss: 0.008614919148385525, train ndcg@10: 0.3573424055911887, ndcg@10: 0.4503731047894409\n",
      "epoch 8 -> loss: 0.008287439122796059, train ndcg@10: 0.36766968062782157, ndcg@10: 0.4341627580062225\n",
      "epoch 9 -> loss: 0.008117688819766045, train ndcg@10: 0.365028847843463, ndcg@10: 0.42525234986019383\n",
      "epoch 0 -> loss: 0.07723575085401535, train ndcg@10: 0.7967690076683716, ndcg@10: 0.789565876754933\n",
      "epoch 1 -> loss: 0.030543828383088112, train ndcg@10: 0.7943715426580188, ndcg@10: 0.7910594883538533\n",
      "epoch 2 -> loss: 0.021090248599648476, train ndcg@10: 0.7937811949323081, ndcg@10: 0.8009930372186348\n",
      "epoch 3 -> loss: 0.01810264401137829, train ndcg@10: 0.7978275719667147, ndcg@10: 0.7922302957789205\n",
      "epoch 4 -> loss: 0.01636059768497944, train ndcg@10: 0.7971972334523794, ndcg@10: 0.8245631280900347\n",
      "epoch 5 -> loss: 0.015984438359737396, train ndcg@10: 0.7994198770220129, ndcg@10: 0.8269342429645358\n",
      "epoch 6 -> loss: 0.015751192346215248, train ndcg@10: 0.7998874889010422, ndcg@10: 0.8289454936960691\n",
      "epoch 7 -> loss: 0.01494795922189951, train ndcg@10: 0.8006654068423324, ndcg@10: 0.8146412051241528\n",
      "epoch 8 -> loss: 0.014277146197855473, train ndcg@10: 0.802015316040952, ndcg@10: 0.8172928979712427\n",
      "epoch 9 -> loss: 0.01456886064261198, train ndcg@10: 0.8062936824985519, ndcg@10: 0.824380928769485\n"
     ]
    }
   ],
   "source": [
    "ltrmodel = LTR.MSE_model(layers=[ds2020.trfm.shape[1], 256, 256, 1], lr=0.001, optimizer=torch.optim.Adam, dropout=0.1)\n",
    "ltrmodel.fit(ds2020, epochs=10, batch_size=100, verbose=True)\n",
    "y_pred2020 = ltrmodel.predict(ds2020.tefm, ds2020.tedlr)\n",
    "\n",
    "ltrmodel = LTR.MSE_model(layers=[ds2019.trfm.shape[1], 256, 256, 1], lr=0.001, optimizer=torch.optim.Adam, dropout=0.1)\n",
    "ltrmodel.fit(ds2019, epochs=10, batch_size=100, verbose=True)\n",
    "y_pred2019 = ltrmodel.predict(ds2019.tefm, ds2019.tedlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Query Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `QueryLearner` class for one query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  5 13  7 10  1  4 11  3  2  9  6 12  0]\n",
      "[ 0 14]\n",
      "0.0826042630947744\n",
      "0.08682031267421593\n",
      "0.08590702204536822\n",
      "0.08289674670647809\n",
      "0.0874206447701937\n",
      "0.08010504353095313\n",
      "0.08261609206241645\n",
      "0.08368211650508939\n",
      "0.08202088588406788\n",
      "0.07617233341554151\n",
      "0.07833836443458368\n",
      "0.07452696181565661\n",
      "0.07006656245057362\n",
      "0.0729837372274111\n",
      "0.06729107335231523\n",
      "0.07798259535663231\n",
      "0.07026930501554844\n",
      "0.06864318862194192\n",
      "0.07015272699750653\n",
      "0.06030687241143994\n",
      "0.07544672715708406\n",
      "0.05327554591569512\n",
      "0.056206461897259495\n",
      "0.06308401940169454\n",
      "0.05588075656411354\n",
      "0.05858725071140732\n",
      "0.05954103304489855\n",
      "0.04804845773549559\n",
      "0.047117885960439664\n",
      "0.04911209512435585\n",
      "0.052674635873865325\n",
      "0.05050824498729071\n",
      "0.044940633239440475\n",
      "0.04682959010532906\n",
      "0.04249167682661406\n",
      "0.04305780390828842\n",
      "0.043866091185220044\n",
      "0.039166828808258364\n",
      "0.031518524881159055\n",
      "0.038420130678958546\n",
      "0.040553995642120755\n",
      "0.04030061776370093\n",
      "0.03625325445635416\n",
      "0.029557779192607072\n",
      "0.03189113737680096\n",
      "0.030772360815770828\n",
      "0.0281408748645133\n",
      "0.02998956461822408\n",
      "0.027058915900272762\n",
      "0.02611130373621817\n"
     ]
    }
   ],
   "source": [
    "qid = 6\n",
    "sessions = 1\n",
    "s, e = ds2020.tedlr[qid:qid+2]\n",
    "y_pred = y_pred2020[s:e]\n",
    "sorted_docs = y_pred.argsort()[::-1]\n",
    "g = ds2020.teg[s:e]\n",
    "\n",
    "\n",
    "# objective_ins = DTR.DTR(y_pred = y_pred, g = g, dlr = None, exposure = np.array([1./np.log2(2+i) for i in range(1,1000)]), method='query_ratio')\n",
    "\n",
    "y, g, sorted_docs, dlr = EEL.copy_sessions(y=y_pred, g=g, sorted=sorted_docs, sessions=sessions)\n",
    "\n",
    "print(sorted_docs)\n",
    "print(dlr)\n",
    "objective_ins = EEL.EEL(y_pred = y, g = g, dlr = dlr, grade_levels=5, exposure = np.array([1./np.log2(2+i) for i in range(1,1000)]))\n",
    "\n",
    "n = y.shape[0]\n",
    "# learner = PPG.Learner(0.5 * np.triu(np.ones((n,n)), 1), samples_cnt=16, \n",
    "#                         objective_ins=objective_ins, sorted_docs=sorted_docs, dlr=dlr, intra=g, inter=np.repeat(dlr[:-1], np.diff(dlr)))\n",
    "# learner = permutationgraph.QueryLearner(objective_ins, sorted_docs = sorted_docs, intra = g)\n",
    "learner = PL.Learner(logits=y, samples_cnt=256, objective_ins=objective_ins)\n",
    "learner.fit(50, 0.1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = PPG.Learner(0.5 * np.triu(np.ones((n,n)), 1), samples_cnt=256, \n",
    "                        objective_ins=objective_ins, sorted_docs=sorted_docs, dlr=dlr, intra=g, inter=np.repeat(dlr[:-1], np.diff(dlr)))\n",
    "learner.fit(50, 0.1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `QueryLearner` class for all queries, using `learn_all_query` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn_all_query(y_pred, g, dlr, exposure, epochs, lr, learner_cls, objective, objective_args=None):\n",
    "    y_rerank = []\n",
    "    sorted_docs = []\n",
    "    min_vals = []\n",
    "    \n",
    "    # for qid in trange(dlr.shape[0] - 1, leave=False):\n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s, e = dlr[qid:qid+2]\n",
    "        if objective == 'DTR':\n",
    "            objective_ins = DTR.DTR(y_pred = y_pred[s:e], g = g[s:e], dlr = None, exposure = exposure, method='query_ratio')\n",
    "        elif objective == 'EEL':\n",
    "            objective_ins = EEL.EEL(y_pred = y_pred[s:e], g = g[s:e], dlr = np.array([0,e-s]), exposure = exposure, **objective_args)\n",
    "\n",
    "        learner = learner_cls(objective_ins, sorted_docs = y_pred[s:e].argsort()[::-1], intra = g[s:e])\n",
    "        vals = learner.fit(epochs, lr, verbose=False)\n",
    "\n",
    "        scores = np.arange(len(learner.sorted_docs), 0, -1)\n",
    "        y_rerank.append(scores[learner.sorted_docs])\n",
    "        sorted_docs.append(learner.sorted_docs)\n",
    "        \n",
    "        vals = np.array(vals)\n",
    "        min_vals.append(vals.min())\n",
    "\n",
    "    # print(ndcg_dtr(exposure, lv, np.concatenate(y_rerank), dlr, g, query_counts))\n",
    "    return np.concatenate(y_rerank), np.concatenate(sorted_docs), np.array(min_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TREC 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 valid queries. --> average: 0.0004992586004082329\n",
      "0.0026061594538377055\n"
     ]
    }
   ],
   "source": [
    "objective='EEL'\n",
    "objective_args = {'grade_levels':2}\n",
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "y_rerank2020, sorted2020, min_vals = learn_all_query(  y_pred2020, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=20, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.QueryLearner,\n",
    "                                            objective=objective,\n",
    "                                            objective_args = objective_args)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries. --> average: {min_vals[min_vals>0].mean()}')\n",
    "\n",
    "if objective == 'DTR':\n",
    "    print(DTR.ndcg_dtr(exposure2020, ds2020.telv, y_rerank2020, ds2020.tedlr, ds2020.teg, ds2020.query_seq))\n",
    "elif objective == 'EEL':\n",
    "    eel = EEL.EEL(y_pred=ds2020.telv, g=ds2020.teg, dlr=ds2020.tedlr, exposure=exposure2020, grade_levels=2)\n",
    "    print(eel.eval(sorted2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with true labels instead of LTR output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 valid queries. --> average: 0.00540273725185993\n",
      "9.125137616866798e-05\n"
     ]
    }
   ],
   "source": [
    "objective='EEL'\n",
    "objective_args = {'grade_levels':2}\n",
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "y_rerank2020, sorted2020, min_vals = learn_all_query(  ds2020.telv, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=5, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.QueryLearner,\n",
    "                                            objective=objective,\n",
    "                                            objective_args = objective_args)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries. --> average: {min_vals[min_vals>0].mean()}')\n",
    "\n",
    "if objective == 'DTR':\n",
    "    print(DTR.ndcg_dtr(exposure2020, ds2020.telv, y_rerank2020, ds2020.tedlr, ds2020.teg, ds2020.query_seq))\n",
    "elif objective == 'EEL':\n",
    "    eel = EEL.EEL(y_pred=ds2020.telv, g=ds2020.teg, dlr=ds2020.tedlr, exposure=exposure2020, grade_levels=2)\n",
    "    print(eel.eval(sorted2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0, 3.4903578476035624e-06, 4.089276234288525e-06]\n",
      "[0.05, 1.8794541399067257e-05, 3.24800807005403e-05]\n",
      "[0.1, 1.7222257762569392e-05, 1.8957449224953783e-05]\n",
      "[0.3, 1.75412902248232e-05, 1.227281485575612e-05]\n",
      "5\n",
      "[0, 1.2160567642181366e-05, 8.629643901219004e-06]\n",
      "[0.05, 1.1491217244884844e-05, 1.3099901826197362e-05]\n",
      "[0.1, 1.3804670305915144e-05, 2.5698098945966977e-05]\n",
      "[0.3, 1.94569482926411e-05, 1.8635912386027702e-05]\n",
      "10\n",
      "[0, 3.582122066188701e-06, 3.2353885845058875e-06]\n",
      "[0.05, 8.798772188069718e-06, 1.3343988574667018e-05]\n",
      "[0.1, 3.877328137464268e-06, 6.882999492179967e-06]\n",
      "[0.3, 9.384055295593371e-06, 9.52857559334133e-06]\n",
      "20\n",
      "[0, 2.6310944979426724e-05, 2.783596015671693e-05]\n",
      "[0.05, 1.6972512263115772e-05, 1.8209822370835188e-05]\n",
      "[0.1, 6.275123822347227e-06, 4.893906194199283e-06]\n",
      "[0.3, 1.3698044535756684e-05, 1.1604093287587913e-05]\n",
      "40\n",
      "[0, 4.475516088413762e-06, 4.505769605885606e-06]\n",
      "[0.05, 1.9392511266385842e-05, 1.2757770422882835e-05]\n",
      "[0.1, 1.9519859634207754e-05, 1.7440469884699275e-05]\n",
      "[0.3, 9.891868191426148e-06, 1.407404795164692e-05]\n",
      "100\n",
      "[0, 8.03849027167086e-06, 1.2626924090587916e-05]\n",
      "[0.05, 1.0381589452736533e-05, 1.213969019018376e-05]\n",
      "[0.1, 1.1228594247012326e-05, 1.5905879997590823e-05]\n",
      "[0.3, 7.5390597438388605e-06, 5.399397654012821e-06]\n"
     ]
    }
   ],
   "source": [
    "def test(epochs, lr):\n",
    "    exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "    y_rerank2020, sorted2020, min_vals = learn_all_query(  ds2020.telv, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=epochs, lr=lr, \n",
    "                                            learner_cls=permutationgraph.QueryLearner,\n",
    "                                            objective=objective,\n",
    "                                            objective_args = {'grade_levels':2})\n",
    "    eel = EEL.EEL(y_pred=ds2020.telv, g=ds2020.teg, dlr=ds2020.tedlr, exposure=exposure2020, grade_levels=2)\n",
    "    return eel.eval(sorted2020)\n",
    "\n",
    "for epochs in [2,5,10,20,40,100]:\n",
    "    print(epochs)\n",
    "    for lr in [0,0.05,0.1,0.3]:\n",
    "        eel = []\n",
    "        for i in range(8):\n",
    "            eel.append(test(5,lr))\n",
    "        eel = np.array(eel)\n",
    "        print([lr, eel.mean(), eel.std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-7894b32c3aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0meel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0meel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0meel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "for lr in [0,0.1,0.3,0.5]:\n",
    "    eel = []\n",
    "    for i in range(8):\n",
    "        eel.append(test(5,lr))\n",
    "    eel = np.array(eel)\n",
    "    print([lr, eel.mean(), eel.std()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TREC 2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554 valid queries.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ndcg@5': 0.6973146692423147,\n",
       " 'ndcg@10': 0.7554091354844698,\n",
       " 'seq DTR': 0.9820242978616949,\n",
       " 'single session DTR': 0.9865777804990237}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exposure2019 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2019.tedlr).max()+2)])\n",
    "y_rerank2019, min_vals = learn_all_query(  y_pred2019, ds2019.teg, ds2019.tedlr, \n",
    "                                            exposure=exposure2019,\n",
    "                                            epochs=50, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.QueryLearner)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries.')\n",
    "DTR.ndcg_dtr(exposure2019, ds2019.telv, y_rerank2019, ds2019.tedlr, ds2019.teg, ds2019.query_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some checks for weirdness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ndcg@5': 0.6947353794524712, 'ndcg@10': 0.769091241344222, 'seq DTR': 0.9569590661138251, 'single session DTR': 0.9981156995633252}\n",
      "{'ndcg@5': 0.7553542778927196, 'ndcg@10': 0.8181533543976589, 'seq DTR': 0.99412071452734, 'single session DTR': 0.9849812607892133}\n",
      "{'ndcg@5': 0.6517401169984236, 'ndcg@10': 0.7206210810470921, 'seq DTR': 0.9864749597040254, 'single session DTR': 0.9927482857791988}\n"
     ]
    }
   ],
   "source": [
    "print(DTR.ndcg_dtr(exposure2019, ds2019.telv, -y_rerank2019, ds2019.tedlr, ds2019.teg, ds2019.query_seq))\n",
    "print(DTR.ndcg_dtr(exposure2019, ds2019.telv, y_pred2019, ds2019.tedlr, ds2019.teg, ds2019.query_seq))\n",
    "print(DTR.ndcg_dtr(exposure2019, ds2019.telv, -y_pred2019, ds2019.tedlr, ds2019.teg, ds2019.query_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Batch Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `BatchLearner` for a set of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_queries(y, g, dlr, qids):\n",
    "    ys, gs, dlrs = [], [], [0]\n",
    "    for qid in qids:\n",
    "        s, e = dlr[qid:qid+2]\n",
    "        ys.append(y[s:e])\n",
    "        gs.append(g[s:e])\n",
    "        dlrs.append(e-s)\n",
    "    return np.concatenate(ys), np.concatenate(gs), np.cumsum(dlrs)\n",
    "\n",
    "qids = [197,  64]\n",
    "y_pred, gs, dlrs = select_queries(ds2020.telv, ds2020.teg, ds2020.tedlr, qids)\n",
    "objective_ins = DTR.DTR(y_pred = y_pred, g = gs, dlr = dlrs, exposure = np.array([1./np.log2(2+i) for i in range(1,1000)]), method='batch_ratio')\n",
    "\n",
    "ss = []\n",
    "for qid in range(dlrs.shape[0] - 1):\n",
    "    s,e = dlrs[qid:qid+2]\n",
    "    ss.append(y_pred[s:e].argsort()[::-1])\n",
    "sorted_docs = np.concatenate(ss)\n",
    "batch_numbers = np.repeat(dlrs[:-1], np.diff(dlrs))\n",
    "learner = permutationgraph.BatchLearner(objective_ins=objective_ins, sorted_docs=sorted_docs, intra=gs, inter=batch_numbers)\n",
    "learner.fit(50, 0.3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `BatchLearner` class for all queries, using `learn_all_batch` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_group_counts(g, dlr):\n",
    "    groups = np.unique(g)\n",
    "    gcnt = [[] for _ in range(len(groups))]\n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s, e = dlr[qid:qid+2]\n",
    "        for i, group in enumerate(groups):\n",
    "            gcnt[i].append(len(np.where(g[s:e] == group)[0]))\n",
    "    for i, group in enumerate(groups):\n",
    "            gcnt[i] = np.array(gcnt[i])\n",
    "    return groups, gcnt\n",
    "\n",
    "\n",
    "def update_y(y, sorted_docs, dlr, qids):\n",
    "    pos = 0\n",
    "    for qid in qids:\n",
    "        s, e = dlr[qid:qid+2]\n",
    "        scores = np.arange(e-s, 0, -1)\n",
    "        y[s:e] = scores[sorted_docs[pos:pos+e-s]]\n",
    "        pos += e-s\n",
    "def learn_all_batch(y_pred, g, dlr, exposure, epochs, lr, learner_cls):\n",
    "    y_rerank = []\n",
    "    min_vals = []\n",
    "    \n",
    "    groups, gcnt = get_group_counts(g, dlr)\n",
    "    for i, _ in enumerate(groups):\n",
    "            gcnt[i] = gcnt[i].argsort()[:, None]\n",
    "    gcnt = np.concatenate(gcnt, axis=1)\n",
    "    \n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s, e = dlr[qid:qid+2]\n",
    "\n",
    "        sorted_docs = y_pred[s:e].argsort()[::-1]\n",
    "\n",
    "        scores = np.arange(len(sorted_docs), 0, -1)\n",
    "        y_rerank.append(scores[sorted_docs])\n",
    "    y_rerank = np.concatenate(y_rerank)\n",
    "\n",
    "    # for bid in trange(dlr.shape[0] - 1, leave=False):\n",
    "    for bid in range(dlr.shape[0] - 1):\n",
    "        qids = gcnt[bid, :]\n",
    "        # print(qids)\n",
    "\n",
    "        ys, gs, dlrs = select_queries(y_rerank, g, dlr, qids)\n",
    "\n",
    "\n",
    "        objective_ins = DTR.DTR(y_pred = ys, g = gs, dlr = dlrs, exposure = exposure, method='batch_ratio')\n",
    "\n",
    "        ss = []\n",
    "        for qid in range(dlrs.shape[0] - 1):\n",
    "            s,e = dlrs[qid:qid+2]\n",
    "            ss.append(ys[s:e].argsort()[::-1])\n",
    "        sorted_docs = np.concatenate(ss)\n",
    "        batch_numbers = np.repeat(dlrs[:-1], np.diff(dlrs))\n",
    "        learner = learner_cls(objective_ins=objective_ins, sorted_docs=sorted_docs, intra=gs, inter=batch_numbers)\n",
    "\n",
    "        vals = learner.fit(epochs, lr, verbose=False)\n",
    "\n",
    "        update_y(y_rerank, learner.sorted_docs, dlr, qids)\n",
    "        \n",
    "        vals = np.array(vals)\n",
    "        min_vals.append(vals.min())\n",
    "\n",
    "        \n",
    "    return y_rerank, np.array(min_vals)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TREC 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 valid queries. --> average: 1.08220164538563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ndcg@5': 0.35520380092632026,\n",
       " 'ndcg@10': 0.3970282016641636,\n",
       " 'seq DTR': 0.30804457586821893,\n",
       " 'single session DTR': 0.7601551338899333}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "y_rerank2020, min_vals = learn_all_batch(  y_pred2020, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=200, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.BatchLearner)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries. --> average: {min_vals[min_vals>0].mean()}')\n",
    "\n",
    "DTR.ndcg_dtr(exposure2020, ds2020.telv, y_rerank2020, ds2020.tedlr, ds2020.teg, ds2020.query_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with true labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 valid queries. --> average: 1.092158462578101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ndcg@5': 0.25129779144086084,\n",
       " 'ndcg@10': 0.2687497832061068,\n",
       " 'seq DTR': 0.30714529671008617,\n",
       " 'single session DTR': 0.7686791385516936}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "y_rerank2020, min_vals = learn_all_batch(  ds2020.telv, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=200, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.BatchLearner)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries. --> average: {min_vals[min_vals>0].mean()}')\n",
    "\n",
    "DTR.ndcg_dtr(exposure2020, ds2020.telv, y_rerank2020, ds2020.tedlr, ds2020.teg, ds2020.query_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Nonrelevant Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'qid':list(np.repeat(ds2019.teqid, np.diff(ds2019.tedlr))), 'group':list(ds2019.teg), 'label':list(ds2019.telv), 'pred':list(y_pred2019)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "learner = permutationgraph.QueryLearner(np.zeros(4), np.arange(n), None, sorted_docs = None)\n",
    "learner.probs_mat = 0.5 * np.ones([learner.n, learner.n])\n",
    "\n",
    "def per2int(docs):\n",
    "    return (np.array([10**(len(docs)-1-i) for i in range(len(docs))])*docs).sum()\n",
    "freq = defaultdict(lambda:0)\n",
    "iters = 50000\n",
    "for _ in range(iters):\n",
    "    docs, crap = learner.permute()\n",
    "    freq[per2int(docs)] += 2.**(n+1)/iters\n",
    "a = sorted(freq.items(),key=lambda x: x[1])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22604073 0.70783217 0.43035958 0.51833013 0.20620828 0.45995174\n",
      " 0.48296419 0.32335147 0.25798429 0.49642818 0.90861669 0.06843116\n",
      " 0.50280473 0.18948366 0.629371   0.74419906 0.55278362 0.63990797\n",
      " 0.16675551 0.45046706]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0., 3., 2., 2., 0., 2., 2., 1., 1., 2., 4., 0., 2., 0., 3., 4., 2.,\n",
       "        3., 0., 2.]),\n",
       " array([0.23170273, 0.39124552, 0.28833521, 0.28833521, 0.23170273,\n",
       "        0.28833521, 0.28833521, 0.24732527, 0.24732527, 0.28833521,\n",
       "        0.56546488, 0.23170273, 0.28833521, 0.23170273, 0.39124552,\n",
       "        0.56546488, 0.28833521, 0.39124552, 0.23170273, 0.28833521])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def linspan(y_pred, levels):\n",
    "    m,M = y_pred.min()-1e-10, y_pred.max()+1e-10\n",
    "    m = max(m,0)\n",
    "    step = (M - m) / levels\n",
    "    return np.floor((y_pred-m)/step)\n",
    "\n",
    "\n",
    "def disc_target_exposure(y, exposure):\n",
    "    sorted_y = np.sort(y)[::-1]\n",
    "    expo = exposure[:len(y)]\n",
    "    te = []\n",
    "    for g in range(int(y.max()+1)):\n",
    "        te.append(np.mean(expo[sorted_y==g]))\n",
    "    return np.array(te)\n",
    "y_pred = np.random.rand(20)\n",
    "\n",
    "\n",
    "exposure = np.array([1./np.log2(2+i) for i in range(1,1000+2)])\n",
    "\n",
    "print(y_pred)\n",
    "a = linspan(y_pred, 5)\n",
    "b = disc_target_exposure(linspan(y_pred, 5), exposure)\n",
    "[a,b[a.astype(int)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f3bdcb0112431a9468416b807a0640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def get_edges(args):\n",
    "    edges = 0\n",
    "    for i in range(len(args)):\n",
    "        for j in range(i+1, len(args)):\n",
    "            if args[i] > args[j]:\n",
    "                edges += 1\n",
    "    return edges\n",
    "\n",
    "def sample(PPG):\n",
    "    n = PPG.shape[0]\n",
    "    if n <= 1:\n",
    "        return np.arange(n)\n",
    "    selected = np.random.binomial(1,PPG)\n",
    "    positions = np.arange(n) + selected.sum(1) - selected.sum(0)\n",
    "    # print(positions)\n",
    "    empty_positions = []\n",
    "    for i in range(n):\n",
    "        shared_i_s = np.where(positions == i)[0]\n",
    "        if len(shared_i_s) <= 1:\n",
    "            if len(shared_i_s) == 0:\n",
    "                empty_positions.append(i)\n",
    "            continue\n",
    "        chosen_i = np.random.choice(shared_i_s)\n",
    "        for j in shared_i_s:\n",
    "            if j == chosen_i:\n",
    "                continue\n",
    "            positions[j] = -1\n",
    "    remaining = np.where(positions == -1)[0]\n",
    "    # print(remaining)\n",
    "    if len(remaining) > 0:\n",
    "        PPG2 = PPG[remaining,:][:,remaining]\n",
    "        positions2 = sample(PPG2)\n",
    "        positions[remaining] = np.array(empty_positions)[positions2]\n",
    "    return positions\n",
    "\n",
    "\n",
    "n = 5\n",
    "prob = 0.3\n",
    "PPG = prob * np.triu(np.ones((n,n)), 1)\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "freq = defaultdict(lambda:defaultdict(lambda:0))\n",
    "\n",
    "iters = 100000\n",
    "for i in trange(iters):\n",
    "    positions = sample(PPG)\n",
    "    edges = get_edges(positions)\n",
    "    freq[edges][str(positions)] += 1./iters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 22, 11.065081174757642, 0.004519090909090883, 0.0011899805540462327, 0.0025000000000000057, 0.0074299999999998655, 0.00040841009999999976]\n",
      "[3, 15, 6.18615895130482, 0.013755333333332941, 0.0029847811012235887, 0.009429999999999784, 0.019789999999999364, 0.002223566099999999]\n",
      "[1, 4, 3.2543559241186224, 0.03939750000000139, 0.0011521149031241689, 0.03775000000000089, 0.040810000000001824, 0.012106082099999993]\n",
      "[0, 1, 2.1832001288016656, 0.06167000000000821, 0.0, 0.06167000000000821, 0.06167000000000821, 0.02824752489999998]\n",
      "[4, 20, 8.183476083755576, 0.0077984999999998516, 0.0025695160536566924, 0.0047799999999999735, 0.013869999999999603, 0.0009529568999999997]\n",
      "[7, 15, 27.381518941105774, 0.0020540000000000016, 0.0011889367799284604, 0.0008300000000000015, 0.004689999999999977, 7.501409999999996e-05]\n",
      "[2, 9, 4.512057070332568, 0.023409999999999216, 0.0034555784207888044, 0.019089999999999392, 0.029789999999998956, 0.005188320899999997]\n",
      "[6, 20, 16.788272376221837, 0.002938499999999998, 0.0013034886842623386, 0.000980000000000002, 0.006049999999999922, 0.00017503289999999991]\n",
      "[8, 9, 45.551930064308515, 0.0014644444444444475, 0.0008121317779100638, 0.000640000000000001, 0.0029100000000000068, 3.2148899999999986e-05]\n",
      "[9, 4, 81.8327635885937, 0.0011275000000000024, 0.00041625563059254935, 0.0006500000000000011, 0.0016600000000000037, 1.3778099999999994e-05]\n",
      "[10, 1, 179.51193076936147, 0.0010600000000000021, 0.0, 0.0010600000000000021, 0.0010600000000000021, 5.9048999999999975e-06]\n"
     ]
    }
   ],
   "source": [
    "for edge in freq:\n",
    "    freq_ = freq[edge]\n",
    "\n",
    "    vals = np.array(list(freq_.values()))\n",
    "    p = (prob**edge)*((1.-prob)**((n*(n-1)/2)-edge))\n",
    "    print([edge, len(vals), vals.mean()/p, vals.mean(), vals.std(), vals.min(), vals.max(), p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[3 2 4 0 1]', 0.0008300000000000015),\n",
       " ('[3 4 0 2 1]', 0.0008900000000000017),\n",
       " ('[3 4 1 0 2]', 0.0012000000000000025),\n",
       " ('[2 4 3 0 1]', 0.0012000000000000025),\n",
       " ('[2 3 4 1 0]', 0.0012300000000000026),\n",
       " ('[4 3 0 1 2]', 0.0012600000000000027),\n",
       " ('[4 0 3 2 1]', 0.0015100000000000033),\n",
       " ('[3 2 1 4 0]', 0.0017000000000000038),\n",
       " ('[3 1 4 2 0]', 0.0017200000000000039),\n",
       " ('[4 2 0 3 1]', 0.0017200000000000039),\n",
       " ('[4 1 3 0 2]', 0.0024000000000000054),\n",
       " ('[2 4 1 3 0]', 0.0024800000000000056),\n",
       " ('[4 2 1 0 3]', 0.003680000000000009),\n",
       " ('[1 4 3 2 0]', 0.004299999999999993),\n",
       " ('[4 1 2 3 0]', 0.004689999999999977)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(freq[7].items()), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 2.4872110503097566]\n",
      "[6, 3.319080265275405]\n",
      "[7, 4.171520581661493]\n",
      "[8, 5.0399984090498915]\n",
      "[9, 5.921294956370677]\n",
      "[10, 6.813066693535745]\n",
      "[11, 7.71356043168727]\n",
      "[12, 8.621431988472054]\n",
      "[13, 9.53562845834332]\n",
      "[14, 10.455309667888933]\n",
      "[15, 11.379794332949729]\n",
      "[16, 12.308522212688034]\n",
      "[17, 13.241026900423323]\n",
      "[18, 14.176915862586243]\n",
      "[19, 15.115855528151963]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def ratio(n):\n",
    "    print([n, np.sqrt(((n*(n-1)/2.) - np.log2(math.factorial(n)))*2)])\n",
    "\n",
    "for i in range(5,20):\n",
    "    ratio(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _neighbors(mat):\n",
    "    neigh = {'upper':{}, 'lower':{}}\n",
    "    n = mat.shape[0]\n",
    "    for i in range(n):\n",
    "        neigh['upper'][i] = []\n",
    "        for j in range(i):\n",
    "            if mat[j,i] == 1:\n",
    "                neigh['upper'][i].append(j)\n",
    "    for i in range(n):\n",
    "        neigh['lower'][i] = []\n",
    "        for j in range(i+1,n):\n",
    "            if mat[i,j] == 1:\n",
    "                neigh['lower'][i].append(j)\n",
    "    return neigh\n",
    "\n",
    "def _insert_to_down(merged, PPG, i_u, up):\n",
    "    Nu = PPG.shape[0]\n",
    "    # print('inserting index', i_u)\n",
    "    # print('merged:', merged)\n",
    "    # print('PPG:', PPG)\n",
    "\n",
    "    if i_u < up.shape[0] - 1:\n",
    "        after_ind = int(np.where(merged == up[i_u + 1])[0])\n",
    "    else:\n",
    "        after_ind = merged.shape[0]\n",
    "\n",
    "    if after_ind == i_u + 1:\n",
    "        # print('no space to move')\n",
    "        return\n",
    "\n",
    "    for i_d in range(i_u+1, after_ind):\n",
    "        q_u, q_d = 0, 0\n",
    "        \n",
    "        for k in range(i_d+1, after_ind):\n",
    "            q_d = q_d * (1. - PPG[merged[i_u]][merged[k]]) + PPG[merged[i_u]][merged[k]]\n",
    "\n",
    "        for k in range(i_u):\n",
    "            q_u = q_u * (1. - PPG[merged[k]][merged[i_d]]) + PPG[merged[k]][merged[i_d]]\n",
    "\n",
    "        q = q_u + q_d - (q_u * q_d)\n",
    "        q *= 1. - PPG[merged[i_u]][merged[i_d]]\n",
    "        if np.random.binomial(1, PPG[merged[i_u]][merged[i_d]] / (1. - q)) == 0:\n",
    "            break\n",
    "\n",
    "    # print('q_u:', q_u, 'q_d:', q_d, 'q:', q, 'p:', PPG[i_u][i_d])\n",
    "    if i_d > i_u + 1:\n",
    "        shift = merged[i_u+1:i_d]\n",
    "        merged_i_u = merged[i_u]\n",
    "        merged[i_u:i_d-1] = shift\n",
    "        merged[i_d-1] = merged_i_u\n",
    "\n",
    "    \n",
    "def get_permutation(selected):\n",
    "    return np.arange(selected.shape[0]) + selected.sum(1) - selected.sum(0)\n",
    "\n",
    "def PPG_merge(up, down, PPG):\n",
    "    Nu = up.shape[0]\n",
    "    Nd = down.shape[0]\n",
    "    \n",
    "    down += Nu\n",
    "    merged = np.concatenate([up, down])\n",
    "    # print('merge -> up:', up)\n",
    "    # print('down:', down)\n",
    "    # print('PPG:', PPG)\n",
    "\n",
    "    for i_u in reversed(range(Nu)):\n",
    "        _insert_to_down(merged, PPG, i_u, up)\n",
    "    return merged\n",
    "\n",
    "def PPG_sample(PPG):\n",
    "    n = PPG.shape[0]\n",
    "    mid = n // 2\n",
    "    # print('main:', n, mid)\n",
    "    if n == 1:\n",
    "        return np.array([0])\n",
    "    if n == 2:\n",
    "        if np.random.binomial(1,PPG[0,1]):\n",
    "            return np.array([1,0])\n",
    "        return np.array([0,1])\n",
    "    up = PPG_sample(PPG[:mid,:][:,:mid])\n",
    "    down = PPG_sample(PPG[mid:,:][:,mid:])\n",
    "    mat = PPG_merge(up, down, PPG)\n",
    "    # print('PPG:', PPG)\n",
    "    # print('mat:', mat)\n",
    "    return mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-b8ad73c1cc84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mPPG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.rand\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.random_sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.double_fill\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 5\n",
    "prob = 0.5 * np.random.rand(n,n)\n",
    "PPG = prob * np.triu(np.ones((n,n)), 1)\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "def get_edges(args):\n",
    "    edges = 0\n",
    "    for i in range(len(args)):\n",
    "        for j in range(i+1, len(args)):\n",
    "            if args[i] > args[j]:\n",
    "                edges += 1\n",
    "    return edges\n",
    "    \n",
    "freq = defaultdict(lambda:defaultdict(lambda:0))\n",
    "\n",
    "iters = 1000\n",
    "for i in trange(iters):\n",
    "    positions = PPG_sample(PPG)\n",
    "    edges = get_edges(positions)\n",
    "    freq[edges][str(positions)] += 1./iters\n",
    "# print(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: 5 count: 4 ratio: 61.44000000000004 max to min: 3.3333333333333335\n",
      "edges: 4 count: 7 ratio: 42.7154285714286 max to min: 4.105263157894737\n",
      "edges: 3 count: 8 ratio: 26.624000000000017 max to min: 3.7142857142857157\n",
      "edges: 2 count: 7 ratio: 18.578285714285727 max to min: 3.888888888888891\n",
      "edges: 1 count: 4 ratio: 13.312000000000005 max to min: 1.6666666666666672\n",
      "edges: 6 count: 1 ratio: 78.84800000000006 max to min: 1.0\n",
      "edges: 0 count: 1 ratio: 4.096 max to min: 1.0\n",
      "[('[4 0 2 1 3]', 0.08100000000000006), ('[2 1 4 0 3]', 0.04200000000000003), ('[3 1 2 0 4]', 0.09000000000000007), ('[1 4 2 0 3]', 0.027000000000000017)]\n",
      "[('[0 4 2 1 3]', 0.03300000000000002), ('[3 0 2 1 4]', 0.07800000000000006), ('[2 0 4 1 3]', 0.04100000000000003), ('[1 4 0 2 3]', 0.03100000000000002), ('[1 3 2 0 4]', 0.046000000000000034), ('[2 1 3 0 4]', 0.04400000000000003), ('[1 2 4 0 3]', 0.01900000000000001)]\n",
      "[('[0 4 1 2 3]', 0.03000000000000002), ('[1 2 0 4 3]', 0.014000000000000005), ('[1 0 4 2 3]', 0.01900000000000001), ('[1 2 3 0 4]', 0.017000000000000008), ('[1 3 0 2 4]', 0.023000000000000013), ('[2 0 3 1 4]', 0.05200000000000004), ('[0 2 4 1 3]', 0.014000000000000005), ('[0 3 2 1 4]', 0.03900000000000003)]\n",
      "[('[0 1 4 2 3]', 0.016000000000000007), ('[0 3 1 2 4]', 0.035000000000000024), ('[0 2 3 1 4]', 0.01800000000000001), ('[1 2 0 3 4]', 0.01900000000000001), ('[1 0 2 4 3]', 0.009000000000000001), ('[1 0 3 2 4]', 0.014000000000000005), ('[0 2 1 4 3]', 0.016000000000000007)]\n",
      "[('[0 1 3 2 4]', 0.015000000000000006), ('[0 1 2 4 3]', 0.015000000000000006), ('[1 0 2 3 4]', 0.009000000000000001), ('[0 2 1 3 4]', 0.013000000000000005)]\n",
      "[('[4 1 2 0 3]', 0.07700000000000005)]\n",
      "[('[0 1 2 3 4]', 0.004)]\n"
     ]
    }
   ],
   "source": [
    "for edge in freq:\n",
    "    freq_ = freq[edge]\n",
    "\n",
    "    vals = np.array(list(freq_.values()))\n",
    "    p = (prob**edge)*((1.-prob)**((n*(n-1)/2)-edge))\n",
    "    print('edges:', edge, 'count:', len(vals), 'ratio:', vals.mean()/p, 'max to min:', vals.max()/vals.min())\n",
    "\n",
    "for edge in freq:\n",
    "    freq_ = list(freq[edge].items())\n",
    "    print(freq_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3., 2.],\n",
       "        [6., 5., 4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "y = np.array([[0,2,1],[2,1,0]])\n",
    "x = torch.FloatTensor(x)\n",
    "y = torch.LongTensor(y)\n",
    "x[torch.arange(x.shape[0]).unsqueeze(1).repeat((1,3)).flatten(), y.flatten()].view(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2, 3),\n",
       " (0, 1, 3, 2),\n",
       " (0, 2, 1, 3),\n",
       " (0, 2, 3, 1),\n",
       " (0, 3, 1, 2),\n",
       " (0, 3, 2, 1),\n",
       " (1, 0, 2, 3),\n",
       " (1, 0, 3, 2),\n",
       " (1, 2, 0, 3),\n",
       " (1, 2, 3, 0),\n",
       " (1, 3, 0, 2),\n",
       " (1, 3, 2, 0),\n",
       " (2, 0, 1, 3),\n",
       " (2, 0, 3, 1),\n",
       " (2, 1, 0, 3),\n",
       " (2, 1, 3, 0),\n",
       " (2, 3, 0, 1),\n",
       " (2, 3, 1, 0),\n",
       " (3, 0, 1, 2),\n",
       " (3, 0, 2, 1),\n",
       " (3, 1, 0, 2),\n",
       " (3, 1, 2, 0),\n",
       " (3, 2, 0, 1),\n",
       " (3, 2, 1, 0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "list(permutations(range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
