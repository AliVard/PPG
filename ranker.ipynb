{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Mmetrics import *\n",
    "\n",
    "import LTR\n",
    "import datautil\n",
    "import permutationgraph\n",
    "import DTR\n",
    "import EEL\n",
    "import PPG\n",
    "import PL\n",
    "\n",
    "ds2020, _ = datautil.load_data(2020, verbose=True)\n",
    "ds2019, _ = datautil.load_data(2019, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a LTR model (MSE)\n",
    "\n",
    "Set `y_pred` using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrmodel = LTR.MSE_model(layers=[ds2020.trfm.shape[1], 256, 256, 1], lr=0.001, optimizer=torch.optim.Adam, dropout=0.1)\n",
    "ltrmodel.fit(ds2020, epochs=10, batch_size=100, verbose=True)\n",
    "y_pred2020 = ltrmodel.predict(ds2020.tefm, ds2020.tedlr)\n",
    "\n",
    "ltrmodel = LTR.MSE_model(layers=[ds2019.trfm.shape[1], 256, 256, 1], lr=0.001, optimizer=torch.optim.Adam, dropout=0.1)\n",
    "ltrmodel.fit(ds2019, epochs=10, batch_size=100, verbose=True)\n",
    "y_pred2019 = ltrmodel.predict(ds2019.tefm, ds2019.tedlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Query Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `QueryLearner` class for one query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid = 6\n",
    "sessions = 1\n",
    "s, e = ds2020.tedlr[qid:qid+2]\n",
    "y_pred = y_pred2020[s:e]\n",
    "sorted_docs = y_pred.argsort()[::-1]\n",
    "g = ds2020.teg[s:e]\n",
    "\n",
    "\n",
    "# objective_ins = DTR.DTR(y_pred = y_pred, g = g, dlr = None, exposure = np.array([1./np.log2(2+i) for i in range(1,1000)]), method='query_ratio')\n",
    "\n",
    "y, g, sorted_docs, dlr = EEL.copy_sessions(y=y_pred, g=g, sorted=sorted_docs, sessions=sessions)\n",
    "\n",
    "print(sorted_docs)\n",
    "print(dlr)\n",
    "objective_ins = EEL.EEL(y_pred = y, g = g, dlr = dlr, grade_levels=5, exposure = np.array([1./np.log2(2+i) for i in range(1,1000)]))\n",
    "\n",
    "n = y.shape[0]\n",
    "# learner = PPG.Learner(0.5 * np.triu(np.ones((n,n)), 1), samples_cnt=16, \n",
    "#                         objective_ins=objective_ins, sorted_docs=sorted_docs, dlr=dlr, intra=g, inter=np.repeat(dlr[:-1], np.diff(dlr)))\n",
    "# learner = permutationgraph.QueryLearner(objective_ins, sorted_docs = sorted_docs, intra = g)\n",
    "learner = PL.Learner(logits=y, samples_cnt=256, objective_ins=objective_ins)\n",
    "learner.fit(50, 0.1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = PPG.Learner(0.5 * np.triu(np.ones((n,n)), 1), samples_cnt=256, \n",
    "                        objective_ins=objective_ins, sorted_docs=sorted_docs, dlr=dlr, intra=g, inter=np.repeat(dlr[:-1], np.diff(dlr)))\n",
    "learner.fit(50, 0.1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `QueryLearner` class for all queries, using `learn_all_query` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn_all_query(y_pred, g, dlr, exposure, epochs, lr, learner_cls, objective, objective_args=None):\n",
    "    y_rerank = []\n",
    "    sorted_docs = []\n",
    "    min_vals = []\n",
    "    \n",
    "    # for qid in trange(dlr.shape[0] - 1, leave=False):\n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s, e = dlr[qid:qid+2]\n",
    "        if objective == 'DTR':\n",
    "            objective_ins = DTR.DTR(y_pred = y_pred[s:e], g = g[s:e], dlr = None, exposure = exposure, method='query_ratio')\n",
    "        elif objective == 'EEL':\n",
    "            objective_ins = EEL.EEL(y_pred = y_pred[s:e], g = g[s:e], dlr = np.array([0,e-s]), exposure = exposure, **objective_args)\n",
    "\n",
    "        learner = learner_cls(objective_ins, sorted_docs = y_pred[s:e].argsort()[::-1], intra = g[s:e])\n",
    "        vals = learner.fit(epochs, lr, verbose=False)\n",
    "\n",
    "        scores = np.arange(len(learner.sorted_docs), 0, -1)\n",
    "        y_rerank.append(scores[learner.sorted_docs])\n",
    "        sorted_docs.append(learner.sorted_docs)\n",
    "        \n",
    "        vals = np.array(vals)\n",
    "        min_vals.append(vals.min())\n",
    "\n",
    "    # print(ndcg_dtr(exposure, lv, np.concatenate(y_rerank), dlr, g, query_counts))\n",
    "    return np.concatenate(y_rerank), np.concatenate(sorted_docs), np.array(min_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TREC 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective='EEL'\n",
    "objective_args = {'grade_levels':2}\n",
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "y_rerank2020, sorted2020, min_vals = learn_all_query(  y_pred2020, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=20, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.QueryLearner,\n",
    "                                            objective=objective,\n",
    "                                            objective_args = objective_args)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries. --> average: {min_vals[min_vals>0].mean()}')\n",
    "\n",
    "if objective == 'DTR':\n",
    "    print(DTR.ndcg_dtr(exposure2020, ds2020.telv, y_rerank2020, ds2020.tedlr, ds2020.teg, ds2020.query_seq))\n",
    "elif objective == 'EEL':\n",
    "    eel = EEL.EEL(y_pred=ds2020.telv, g=ds2020.teg, dlr=ds2020.tedlr, exposure=exposure2020, grade_levels=2)\n",
    "    print(eel.eval(sorted2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with true labels instead of LTR output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective='EEL'\n",
    "objective_args = {'grade_levels':2}\n",
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "y_rerank2020, sorted2020, min_vals = learn_all_query(  ds2020.telv, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=5, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.QueryLearner,\n",
    "                                            objective=objective,\n",
    "                                            objective_args = objective_args)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries. --> average: {min_vals[min_vals>0].mean()}')\n",
    "\n",
    "if objective == 'DTR':\n",
    "    print(DTR.ndcg_dtr(exposure2020, ds2020.telv, y_rerank2020, ds2020.tedlr, ds2020.teg, ds2020.query_seq))\n",
    "elif objective == 'EEL':\n",
    "    eel = EEL.EEL(y_pred=ds2020.telv, g=ds2020.teg, dlr=ds2020.tedlr, exposure=exposure2020, grade_levels=2)\n",
    "    print(eel.eval(sorted2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epochs, lr):\n",
    "    exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "    y_rerank2020, sorted2020, min_vals = learn_all_query(  ds2020.telv, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=epochs, lr=lr, \n",
    "                                            learner_cls=permutationgraph.QueryLearner,\n",
    "                                            objective=objective,\n",
    "                                            objective_args = {'grade_levels':2})\n",
    "    eel = EEL.EEL(y_pred=ds2020.telv, g=ds2020.teg, dlr=ds2020.tedlr, exposure=exposure2020, grade_levels=2)\n",
    "    return eel.eval(sorted2020)\n",
    "\n",
    "for epochs in [2,5,10,20,40,100]:\n",
    "    print(epochs)\n",
    "    for lr in [0,0.05,0.1,0.3]:\n",
    "        eel = []\n",
    "        for i in range(8):\n",
    "            eel.append(test(5,lr))\n",
    "        eel = np.array(eel)\n",
    "        print([lr, eel.mean(), eel.std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for lr in [0,0.1,0.3,0.5]:\n",
    "    eel = []\n",
    "    for i in range(8):\n",
    "        eel.append(test(5,lr))\n",
    "    eel = np.array(eel)\n",
    "    print([lr, eel.mean(), eel.std()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TREC 2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure2019 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2019.tedlr).max()+2)])\n",
    "y_rerank2019, min_vals = learn_all_query(  y_pred2019, ds2019.teg, ds2019.tedlr, \n",
    "                                            exposure=exposure2019,\n",
    "                                            epochs=50, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.QueryLearner)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries.')\n",
    "DTR.ndcg_dtr(exposure2019, ds2019.telv, y_rerank2019, ds2019.tedlr, ds2019.teg, ds2019.query_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some checks for weirdness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DTR.ndcg_dtr(exposure2019, ds2019.telv, -y_rerank2019, ds2019.tedlr, ds2019.teg, ds2019.query_seq))\n",
    "print(DTR.ndcg_dtr(exposure2019, ds2019.telv, y_pred2019, ds2019.tedlr, ds2019.teg, ds2019.query_seq))\n",
    "print(DTR.ndcg_dtr(exposure2019, ds2019.telv, -y_pred2019, ds2019.tedlr, ds2019.teg, ds2019.query_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Batch Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `BatchLearner` for a set of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_queries(y, g, dlr, qids):\n",
    "    ys, gs, dlrs = [], [], [0]\n",
    "    for qid in qids:\n",
    "        s, e = dlr[qid:qid+2]\n",
    "        ys.append(y[s:e])\n",
    "        gs.append(g[s:e])\n",
    "        dlrs.append(e-s)\n",
    "    return np.concatenate(ys), np.concatenate(gs), np.cumsum(dlrs)\n",
    "\n",
    "qids = [197,  64]\n",
    "y_pred, gs, dlrs = select_queries(ds2020.telv, ds2020.teg, ds2020.tedlr, qids)\n",
    "objective_ins = DTR.DTR(y_pred = y_pred, g = gs, dlr = dlrs, exposure = np.array([1./np.log2(2+i) for i in range(1,1000)]), method='batch_ratio')\n",
    "\n",
    "ss = []\n",
    "for qid in range(dlrs.shape[0] - 1):\n",
    "    s,e = dlrs[qid:qid+2]\n",
    "    ss.append(y_pred[s:e].argsort()[::-1])\n",
    "sorted_docs = np.concatenate(ss)\n",
    "batch_numbers = np.repeat(dlrs[:-1], np.diff(dlrs))\n",
    "learner = permutationgraph.BatchLearner(objective_ins=objective_ins, sorted_docs=sorted_docs, intra=gs, inter=batch_numbers)\n",
    "learner.fit(50, 0.3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `BatchLearner` class for all queries, using `learn_all_batch` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_group_counts(g, dlr):\n",
    "    groups = np.unique(g)\n",
    "    gcnt = [[] for _ in range(len(groups))]\n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s, e = dlr[qid:qid+2]\n",
    "        for i, group in enumerate(groups):\n",
    "            gcnt[i].append(len(np.where(g[s:e] == group)[0]))\n",
    "    for i, group in enumerate(groups):\n",
    "            gcnt[i] = np.array(gcnt[i])\n",
    "    return groups, gcnt\n",
    "\n",
    "\n",
    "def update_y(y, sorted_docs, dlr, qids):\n",
    "    pos = 0\n",
    "    for qid in qids:\n",
    "        s, e = dlr[qid:qid+2]\n",
    "        scores = np.arange(e-s, 0, -1)\n",
    "        y[s:e] = scores[sorted_docs[pos:pos+e-s]]\n",
    "        pos += e-s\n",
    "def learn_all_batch(y_pred, g, dlr, exposure, epochs, lr, learner_cls):\n",
    "    y_rerank = []\n",
    "    min_vals = []\n",
    "    \n",
    "    groups, gcnt = get_group_counts(g, dlr)\n",
    "    for i, _ in enumerate(groups):\n",
    "            gcnt[i] = gcnt[i].argsort()[:, None]\n",
    "    gcnt = np.concatenate(gcnt, axis=1)\n",
    "    \n",
    "    for qid in range(dlr.shape[0] - 1):\n",
    "        s, e = dlr[qid:qid+2]\n",
    "\n",
    "        sorted_docs = y_pred[s:e].argsort()[::-1]\n",
    "\n",
    "        scores = np.arange(len(sorted_docs), 0, -1)\n",
    "        y_rerank.append(scores[sorted_docs])\n",
    "    y_rerank = np.concatenate(y_rerank)\n",
    "\n",
    "    # for bid in trange(dlr.shape[0] - 1, leave=False):\n",
    "    for bid in range(dlr.shape[0] - 1):\n",
    "        qids = gcnt[bid, :]\n",
    "        # print(qids)\n",
    "\n",
    "        ys, gs, dlrs = select_queries(y_rerank, g, dlr, qids)\n",
    "\n",
    "\n",
    "        objective_ins = DTR.DTR(y_pred = ys, g = gs, dlr = dlrs, exposure = exposure, method='batch_ratio')\n",
    "\n",
    "        ss = []\n",
    "        for qid in range(dlrs.shape[0] - 1):\n",
    "            s,e = dlrs[qid:qid+2]\n",
    "            ss.append(ys[s:e].argsort()[::-1])\n",
    "        sorted_docs = np.concatenate(ss)\n",
    "        batch_numbers = np.repeat(dlrs[:-1], np.diff(dlrs))\n",
    "        learner = learner_cls(objective_ins=objective_ins, sorted_docs=sorted_docs, intra=gs, inter=batch_numbers)\n",
    "\n",
    "        vals = learner.fit(epochs, lr, verbose=False)\n",
    "\n",
    "        update_y(y_rerank, learner.sorted_docs, dlr, qids)\n",
    "        \n",
    "        vals = np.array(vals)\n",
    "        min_vals.append(vals.min())\n",
    "\n",
    "        \n",
    "    return y_rerank, np.array(min_vals)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TREC 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "y_rerank2020, min_vals = learn_all_batch(  y_pred2020, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=200, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.BatchLearner)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries. --> average: {min_vals[min_vals>0].mean()}')\n",
    "\n",
    "DTR.ndcg_dtr(exposure2020, ds2020.telv, y_rerank2020, ds2020.tedlr, ds2020.teg, ds2020.query_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with true labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure2020 = np.array([1./np.log2(2+i) for i in range(1,np.diff(ds2020.tedlr).max()+2)])\n",
    "y_rerank2020, min_vals = learn_all_batch(  ds2020.telv, ds2020.teg, ds2020.tedlr, \n",
    "                                            exposure = exposure2020,\n",
    "                                            epochs=200, lr=0.3, \n",
    "                                            learner_cls=permutationgraph.BatchLearner)\n",
    "print(f'{len(min_vals[min_vals>0])} valid queries. --> average: {min_vals[min_vals>0].mean()}')\n",
    "\n",
    "DTR.ndcg_dtr(exposure2020, ds2020.telv, y_rerank2020, ds2020.tedlr, ds2020.teg, ds2020.query_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Nonrelevant Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'qid':list(np.repeat(ds2019.teqid, np.diff(ds2019.tedlr))), 'group':list(ds2019.teg), 'label':list(ds2019.telv), 'pred':list(y_pred2019)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "learner = permutationgraph.QueryLearner(np.zeros(4), np.arange(n), None, sorted_docs = None)\n",
    "learner.probs_mat = 0.5 * np.ones([learner.n, learner.n])\n",
    "\n",
    "def per2int(docs):\n",
    "    return (np.array([10**(len(docs)-1-i) for i in range(len(docs))])*docs).sum()\n",
    "freq = defaultdict(lambda:0)\n",
    "iters = 50000\n",
    "for _ in range(iters):\n",
    "    docs, crap = learner.permute()\n",
    "    freq[per2int(docs)] += 2.**(n+1)/iters\n",
    "a = sorted(freq.items(),key=lambda x: x[1])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linspan(y_pred, levels):\n",
    "    m,M = y_pred.min()-1e-10, y_pred.max()+1e-10\n",
    "    m = max(m,0)\n",
    "    step = (M - m) / levels\n",
    "    return np.floor((y_pred-m)/step)\n",
    "\n",
    "\n",
    "def disc_target_exposure(y, exposure):\n",
    "    sorted_y = np.sort(y)[::-1]\n",
    "    expo = exposure[:len(y)]\n",
    "    te = []\n",
    "    for g in range(int(y.max()+1)):\n",
    "        te.append(np.mean(expo[sorted_y==g]))\n",
    "    return np.array(te)\n",
    "y_pred = np.random.rand(20)\n",
    "\n",
    "\n",
    "exposure = np.array([1./np.log2(2+i) for i in range(1,1000+2)])\n",
    "\n",
    "print(y_pred)\n",
    "a = linspan(y_pred, 5)\n",
    "b = disc_target_exposure(linspan(y_pred, 5), exposure)\n",
    "[a,b[a.astype(int)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_edges(args):\n",
    "    edges = 0\n",
    "    for i in range(len(args)):\n",
    "        for j in range(i+1, len(args)):\n",
    "            if args[i] > args[j]:\n",
    "                edges += 1\n",
    "    return edges\n",
    "\n",
    "def sample(PPG):\n",
    "    n = PPG.shape[0]\n",
    "    if n <= 1:\n",
    "        return np.arange(n)\n",
    "    selected = np.random.binomial(1,PPG)\n",
    "    positions = np.arange(n) + selected.sum(1) - selected.sum(0)\n",
    "    # print(positions)\n",
    "    empty_positions = []\n",
    "    for i in range(n):\n",
    "        shared_i_s = np.where(positions == i)[0]\n",
    "        if len(shared_i_s) <= 1:\n",
    "            if len(shared_i_s) == 0:\n",
    "                empty_positions.append(i)\n",
    "            continue\n",
    "        chosen_i = np.random.choice(shared_i_s)\n",
    "        for j in shared_i_s:\n",
    "            if j == chosen_i:\n",
    "                continue\n",
    "            positions[j] = -1\n",
    "    remaining = np.where(positions == -1)[0]\n",
    "    # print(remaining)\n",
    "    if len(remaining) > 0:\n",
    "        PPG2 = PPG[remaining,:][:,remaining]\n",
    "        positions2 = sample(PPG2)\n",
    "        positions[remaining] = np.array(empty_positions)[positions2]\n",
    "    return positions\n",
    "\n",
    "\n",
    "n = 5\n",
    "prob = 0.3\n",
    "PPG = prob * np.triu(np.ones((n,n)), 1)\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "freq = defaultdict(lambda:defaultdict(lambda:0))\n",
    "\n",
    "iters = 100000\n",
    "for i in trange(iters):\n",
    "    positions = sample(PPG)\n",
    "    edges = get_edges(positions)\n",
    "    freq[edges][str(positions)] += 1./iters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in freq:\n",
    "    freq_ = freq[edge]\n",
    "\n",
    "    vals = np.array(list(freq_.values()))\n",
    "    p = (prob**edge)*((1.-prob)**((n*(n-1)/2)-edge))\n",
    "    print([edge, len(vals), vals.mean()/p, vals.mean(), vals.std(), vals.min(), vals.max(), p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(freq[7].items()), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def ratio(n):\n",
    "    print([n, np.sqrt(((n*(n-1)/2.) - np.log2(math.factorial(n)))*2)])\n",
    "\n",
    "for i in range(5,20):\n",
    "    ratio(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _neighbors(mat):\n",
    "    neigh = {'upper':{}, 'lower':{}}\n",
    "    n = mat.shape[0]\n",
    "    for i in range(n):\n",
    "        neigh['upper'][i] = []\n",
    "        for j in range(i):\n",
    "            if mat[j,i] == 1:\n",
    "                neigh['upper'][i].append(j)\n",
    "    for i in range(n):\n",
    "        neigh['lower'][i] = []\n",
    "        for j in range(i+1,n):\n",
    "            if mat[i,j] == 1:\n",
    "                neigh['lower'][i].append(j)\n",
    "    return neigh\n",
    "\n",
    "def _insert_to_down(merged, PPG, i_u, up):\n",
    "    Nu = PPG.shape[0]\n",
    "    # print('inserting index', i_u)\n",
    "    # print('merged:', merged)\n",
    "    # print('PPG:', PPG)\n",
    "\n",
    "    if i_u < up.shape[0] - 1:\n",
    "        after_ind = int(np.where(merged == up[i_u + 1])[0])\n",
    "    else:\n",
    "        after_ind = merged.shape[0]\n",
    "\n",
    "    if after_ind == i_u + 1:\n",
    "        # print('no space to move')\n",
    "        return\n",
    "\n",
    "    for i_d in range(i_u+1, after_ind):\n",
    "        q_u, q_d = 0, 0\n",
    "        \n",
    "        for k in range(i_d+1, after_ind):\n",
    "            q_d = q_d * (1. - PPG[merged[i_u]][merged[k]]) + PPG[merged[i_u]][merged[k]]\n",
    "\n",
    "        for k in range(i_u):\n",
    "            q_u = q_u * (1. - PPG[merged[k]][merged[i_d]]) + PPG[merged[k]][merged[i_d]]\n",
    "\n",
    "        q = q_u + q_d - (q_u * q_d)\n",
    "        q *= 1. - PPG[merged[i_u]][merged[i_d]]\n",
    "        if np.random.binomial(1, PPG[merged[i_u]][merged[i_d]] / (1. - q)) == 0:\n",
    "            break\n",
    "\n",
    "    # print('q_u:', q_u, 'q_d:', q_d, 'q:', q, 'p:', PPG[i_u][i_d])\n",
    "    if i_d > i_u + 1:\n",
    "        shift = merged[i_u+1:i_d]\n",
    "        merged_i_u = merged[i_u]\n",
    "        merged[i_u:i_d-1] = shift\n",
    "        merged[i_d-1] = merged_i_u\n",
    "\n",
    "    \n",
    "def get_permutation(selected):\n",
    "    return np.arange(selected.shape[0]) + selected.sum(1) - selected.sum(0)\n",
    "\n",
    "def PPG_merge(up, down, PPG):\n",
    "    Nu = up.shape[0]\n",
    "    Nd = down.shape[0]\n",
    "    \n",
    "    down += Nu\n",
    "    merged = np.concatenate([up, down])\n",
    "    # print('merge -> up:', up)\n",
    "    # print('down:', down)\n",
    "    # print('PPG:', PPG)\n",
    "\n",
    "    for i_u in reversed(range(Nu)):\n",
    "        _insert_to_down(merged, PPG, i_u, up)\n",
    "    return merged\n",
    "\n",
    "def PPG_sample(PPG):\n",
    "    n = PPG.shape[0]\n",
    "    mid = n // 2\n",
    "    # print('main:', n, mid)\n",
    "    if n == 1:\n",
    "        return np.array([0])\n",
    "    if n == 2:\n",
    "        if np.random.binomial(1,PPG[0,1]):\n",
    "            return np.array([1,0])\n",
    "        return np.array([0,1])\n",
    "    up = PPG_sample(PPG[:mid,:][:,:mid])\n",
    "    down = PPG_sample(PPG[mid:,:][:,mid:])\n",
    "    mat = PPG_merge(up, down, PPG)\n",
    "    # print('PPG:', PPG)\n",
    "    # print('mat:', mat)\n",
    "    return mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 5\n",
    "prob = 0.5 * np.random.rand(n,n)\n",
    "PPG = prob * np.triu(np.ones((n,n)), 1)\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "def get_edges(args):\n",
    "    edges = 0\n",
    "    for i in range(len(args)):\n",
    "        for j in range(i+1, len(args)):\n",
    "            if args[i] > args[j]:\n",
    "                edges += 1\n",
    "    return edges\n",
    "    \n",
    "freq = defaultdict(lambda:defaultdict(lambda:0))\n",
    "\n",
    "iters = 1000\n",
    "for i in trange(iters):\n",
    "    positions = PPG_sample(PPG)\n",
    "    edges = get_edges(positions)\n",
    "    freq[edges][str(positions)] += 1./iters\n",
    "# print(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in freq:\n",
    "    freq_ = freq[edge]\n",
    "\n",
    "    vals = np.array(list(freq_.values()))\n",
    "    p = (prob**edge)*((1.-prob)**((n*(n-1)/2)-edge))\n",
    "    print('edges:', edge, 'count:', len(vals), 'ratio:', vals.mean()/p, 'max to min:', vals.max()/vals.min())\n",
    "\n",
    "for edge in freq:\n",
    "    freq_ = list(freq[edge].items())\n",
    "    print(freq_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "y = np.array([[0,2,1],[2,1,0]])\n",
    "x = torch.FloatTensor(x)\n",
    "y = torch.LongTensor(y)\n",
    "x[torch.arange(x.shape[0]).unsqueeze(1).repeat((1,3)).flatten(), y.flatten()].view(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "list(permutations(range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
